interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "Hey, how''s it going?"}], "model":
      "gpt-4o-mini", "max_tokens": 200, "seed": 47, "temperature": 0.0}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '142'
      content-type:
      - application/json
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.63.2
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.63.2
      x-stainless-raw-response:
      - 'true'
      x-stainless-read-timeout:
      - '10.0'
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.9
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//jFI9b9swEN31K65culiF5S85XgJkaBJ0K4ouRSHQ5FmiQ/FY8tTWCfzf
        C0qO5SApkIXDe3eP793dUwYgjBYbEKqRrFpv85vy4fPV+sut38rbx3hzx/u9Lopf3789Lr4aMUkd
        tN2j4ueuT4pab5ENuYFWASVjUi3KRVGsl+Vy2RMtabSprfacLyhvjTP5bDpb5NMyL9an7oaMwig2
        8CMDAHjq3+TTafwrNjCdPCMtxihrFJtzEYAIZBMiZIwmsnQsJiOpyDG63vr9xxb2XWSQ4APVQbYT
        2HYMCW8wIEinIaDUB2CCBq2HA3Uf4I7+gJIO7mH4IaHApOXh+vKngLsuypTWddae8OPZuqXaB9rG
        E3/Gd8aZ2FQBZSSXbEYmL3r2mAH87EfUvUgtfKDWc8X0gC4JFotBToyLGcnZ7EQysbQjPl9N3lCr
        NLI0Nl6MWCipGtRj57gP2WlDF0R2kfm1mbe0h9zG1e+RHwml0DPqygfURr0MPJYFTGf7v7LzjHvD
        ImL4bRRWbDCkPWjcyc4OxyTiITK21c64GoMPZriona+mq3Jeyqv5dCWyY/YPAAD//wMAISbebV8D
        AAA=
    headers:
      CF-RAY:
      - 91ba617b7bdbe1c5-MRS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 05 Mar 2025 14:42:36 GMT
      Server:
      - cloudflare
      Set-Cookie:
      - __cf_bm=c1h7f3pgmJnxVC9rHGs3te06zBcKSRVGzMU8P38meFI-1741185756-1.0.1.1-rqUHt_4pGjchhjNybSljrN8neSyVq6M_qw75U5IIkkL5kx2cIJFomg8WZ_fno0PWbLSVbBPfBZP72Z4b31LpIDfTTlvIjmg13of4F2L.nco;
        path=/; expires=Wed, 05-Mar-25 15:12:36 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=SoHaBftf_YDh4Gf9ph81lhqx5l.JGWYXxG69w3Nv4mM-1741185756337-0.0.1.1-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      cf-cache-status:
      - DYNAMIC
      openai-organization:
      - heartex
      openai-processing-ms:
      - '454'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149999793'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_68b3e85b07febd88811fc98a323781f5
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "\n                    Given
      the github issue title:\nI can''t login\n and the description:\nI can''t login
      to the platform\n, \n                    classify the issue. Provide a rationale
      for your classification. \n                    Evaluate the final classification
      on a Likert scale from 1 to 5, \n                    where 1 is \"Completely
      irrelevant\" and 5 is \"Completely relevant\"."}], "model": "gpt-4o-mini", "max_tokens":
      200, "seed": 47, "temperature": 0.0, "tool_choice": {"type": "function", "function":
      {"name": "MyModel"}}, "tools": [{"type": "function", "function": {"name": "MyModel",
      "description": "Correctly extracted `MyModel` with all the required parameters
      with correct types", "parameters": {"properties": {"classification": {"description":
      "Choices for [''title'']", "enum": ["Bug report", "Feature request", "Question",
      "Other"], "title": "Classification", "type": "string"}, "evaluation": {"description":
      "Rating for [''title''] (0 to 5)", "maximum": 5, "minimum": 0, "title": "Evaluation",
      "type": "integer"}, "rationale": {"anyOf": [{"items": {"type": "string"}, "type":
      "array"}, {"type": "null"}], "default": null, "description": "List of texts
      (one or more) for [''title'']", "title": "Rationale"}}, "required": ["classification",
      "evaluation"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1338'
      content-type:
      - application/json
      cookie:
      - __cf_bm=c1h7f3pgmJnxVC9rHGs3te06zBcKSRVGzMU8P38meFI-1741185756-1.0.1.1-rqUHt_4pGjchhjNybSljrN8neSyVq6M_qw75U5IIkkL5kx2cIJFomg8WZ_fno0PWbLSVbBPfBZP72Z4b31LpIDfTTlvIjmg13of4F2L.nco;
        _cfuvid=SoHaBftf_YDh4Gf9ph81lhqx5l.JGWYXxG69w3Nv4mM-1741185756337-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.63.2
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.63.2
      x-stainless-raw-response:
      - 'true'
      x-stainless-read-timeout:
      - '10.0'
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.9
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//jFRLT9tAEL7nV4zmnKAkJCTxDZDgUCGqlvZQjKxlPbaX7MPsAxpF+e/V
        Ok7sUCrVB2s938w33zy82wEAihwTQF4xz1UtR1eL9c3l9e236usL2fdfs1d2m5ffvTEPq1ePwxhh
        nl+I+0PUGTeqluSF0XuYW2KeIutkMZtMlvPF/KIBlMlJxrCy9qOZGSmhxWg6ns5G48VosmyjKyM4
        OUzgcQAAsG3eUafO6TcmMB4eLIqcYyVhcnQCQGtktCBzTjjP9F5zC3KjPekoXQcpe4A3RmacSdkl
        3j/b3rlrFpMyWy7v9Zf72c/p2s5pfad+UKWWN5fXvXx76k3dCCqC5scm9fCjPfmQDAA1U03s3eau
        6d3wowOzZVCkfZSN2xS5jHUXgrNImWKS4lUowVJtrE9xmCK9MRkO6HyYom0+mKQUk8cUHyoC4Vwg
        4JKYlRsQOo985IBBbc2zJAXvwlcgTVkKXYLQQ3ivBK9ARB9ulDIankMJvmIegiPrQLENkOYmaE8W
        jI5kkvnCWHWW4tMOT0rbDT47P/UmZqkIjsl2lK19d9wNacqo1X0YNRZCC1dllphrWo7Om3qfO+Zp
        MmA4WSusrVG1z7xZk46E02m7g9itfoeer1rQG89kL2p+AE74spw8E83eHVedM15R3oV2K89CLkwP
        GPSq/lvNZ9z7yoUu/4e+Azin2lOe1ZZywU8r7twsxZvhX27HLjeC0ZF9E5wyL8jGSeRUsCDbO8Zt
        nCeVFUKXZGsrmp8WizobXyzOF2x1Pr7AwW7wBwAA//8DANfO8t3CBAAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 91ba61841a81e1c5-MRS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 05 Mar 2025 14:42:38 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '1434'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149999703'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_98214ec85123e93265b03ccdcef86e68
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "\n                    Given
      the github issue title:\nSupport new file types\n and the description:\nIt would
      be great if we could upload files of type .docx\n, \n                    classify
      the issue. Provide a rationale for your classification. \n                    Evaluate
      the final classification on a Likert scale from 1 to 5, \n                    where
      1 is \"Completely irrelevant\" and 5 is \"Completely relevant\"."}], "model":
      "gpt-4o-mini", "max_tokens": 200, "seed": 47, "temperature": 0.0, "tool_choice":
      {"type": "function", "function": {"name": "MyModel"}}, "tools": [{"type": "function",
      "function": {"name": "MyModel", "description": "Correctly extracted `MyModel`
      with all the required parameters with correct types", "parameters": {"properties":
      {"classification": {"description": "Choices for [''title'']", "enum": ["Bug
      report", "Feature request", "Question", "Other"], "title": "Classification",
      "type": "string"}, "evaluation": {"description": "Rating for [''title''] (0
      to 5)", "maximum": 5, "minimum": 0, "title": "Evaluation", "type": "integer"},
      "rationale": {"anyOf": [{"items": {"type": "string"}, "type": "array"}, {"type":
      "null"}], "default": null, "description": "List of texts (one or more) for [''title'']",
      "title": "Rationale"}}, "required": ["classification", "evaluation"], "type":
      "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1374'
      content-type:
      - application/json
      cookie:
      - __cf_bm=c1h7f3pgmJnxVC9rHGs3te06zBcKSRVGzMU8P38meFI-1741185756-1.0.1.1-rqUHt_4pGjchhjNybSljrN8neSyVq6M_qw75U5IIkkL5kx2cIJFomg8WZ_fno0PWbLSVbBPfBZP72Z4b31LpIDfTTlvIjmg13of4F2L.nco;
        _cfuvid=SoHaBftf_YDh4Gf9ph81lhqx5l.JGWYXxG69w3Nv4mM-1741185756337-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.63.2
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.63.2
      x-stainless-raw-response:
      - 'true'
      x-stainless-read-timeout:
      - '10.0'
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.9
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//jFTbTuMwEH3vV4zmOUVtoU3pG1Sw0iLYi3a1QgRFxpkkXhzb2A7QVv33
        lZO2CSwrbR6sZM6cOXPxZDMAQJHhApCXzPPKyOF5/Hi5zH7eTFcXk5v150+TX2evT+eFXL7eni0x
        Cgz98Ju437OOuK6MJC+0amFuiXkKUcfxyXg8n8bTeQNUOiMZaIXxwxM9rIQSw8locjIcxcPxfMcu
        teDkcAF3AwCATXOGPFVGr7iAUbS3VOQcKwgXBycAtFoGCzLnhPNMeYw6kGvlSYXUVS1lD/Bay5Qz
        KTvh9tn03rtmMSlTMV9dXX1dX+Rfqu+z8lt8u1wWtVjHPb029Mo0CeW14ocm9fCDffFODAAVqxru
        9eq66V303oHZoq5I+ZA2bhLkMtSdC85CyAQXCV4S87UlsPRUk/MJRgnSM5P13mUaJWibDyYpwcVd
        gj9KAuFcHc49UagCXG2Mth5ybYGBohfIhSQIJUbwUgpeglBZUCcHDDJywlLrnWWilYB9wUwKvwKh
        wJcEzBi5y/oowfstvql0O/jo/b43QEt57ZjcTXZn3x6uitSFsfrBvZs85kIJV6aWmGsmgM5r02oH
        nUYB6ze3DI3VlfGp14+kQsDJ5LSNh90mdOjxfAd67ZnssWZx9EG8NCPPRHMNDzefM15S1lG7DWB1
        JnQPGPSq/jubj2K3lQtV/E/4DuCcjKcsNZYywd9W3LlZCj+Kf7kdutwkjI7ss+CUekE2TCKjnNWy
        XV90K+epSnOhCrLGimaHMTfpaBYfx+z0eDTDwXbwBwAA//8DALV5NRzRBAAA
    headers:
      CF-RAY:
      - 91ba618e5ca6e1c5-MRS
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Wed, 05 Mar 2025 14:42:39 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      cf-cache-status:
      - DYNAMIC
      openai-organization:
      - heartex
      openai-processing-ms:
      - '725'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149999694'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_422e919fc29fab5b3688116f24b3d0e9
    status:
      code: 200
      message: OK
version: 1
