interactions:
- request:
    body: '{"contents": [{"role": "user", "parts": [{"text": "Hello, how are you?"}]}],
      "generationConfig": {}}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '100'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
      user-agent:
      - litellm/1.65.6
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAC/61R0U6DMBR95ytqnzczmAz0xRg1ccZlixKjUWOucscaSkto2cRl/24B2br5ah+a
        5p7Te+49Z+0QQj9BxCwGjYqekRdTIWTd3DUmhUahDdCVTDGHQu+47Vlbb0PR+FV/omMCGYklEwlZ
        Iec9ohcgUlLJksxlQUClBjoiN3JFoMCmrmUM1fmroFbHzfb91tvNUUiOtUgmY+QdfdMR6JwJphb3
        CEqKmvYQTWd0i8IyuZNJXsiPepX+4HgwDAI3dId+OBr6J57vB04n3YjSUkGCE9RgvIKtI9S0yHId
        yRTFpSwbr0atiuXsHux2uJYa+B7keb0/XdWV0WTcdtwKwywPnOmq3jC6foqoZZDeG6ozyLF8PBzx
        n7TcAzHnN5c2qkcsFGszSTAzKfW940F/zkEtmo60QJVLoXAc1xw2Ll2Y4vvt8zcLJuHsdLoMq4uU
        OhvnBxC84mHAAgAA
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Mon, 01 Sep 2025 12:03:20 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=423
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Hello, how are you?"}], "model":
      "gemini/gemini-2.0-flash"}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '102'
      content-type:
      - application/json
      host:
      - localhost:30001
      user-agent:
      - AsyncOpenAI/Python 1.76.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.76.0
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.12
    method: POST
    uri: http://localhost:30001/chat/completions
  response:
    body:
      string: '{"id":"chatcmpl-26e1bc3a-2b1a-4917-bb03-49e951b15c35","object":"chat.completion","created":1756728200,"model":"gemini-2.0-flash","choices":[{"finish_reason":"stop","index":0,"message":{"content":"I
        am doing well, thank you for asking! How are you today?\n","role":"assistant","tool_calls":null,"function_call":null},"logprobs":-0.03771813586354256}],"usage":{"completion_tokens":16,"prompt_tokens":6,"total_tokens":22,"completion_tokens_details":null,"prompt_tokens_details":{"audio_tokens":null,"cached_tokens":null}},"service_tier":"default"}'
    headers:
      content-length:
      - '544'
      content-type:
      - application/json
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Hello, how are you?"}], "model":
      "gemini/gemini-2.0-flash"}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      base_url:
      - http://non.existent.endpoint
      connection:
      - keep-alive
      content-length:
      - '102'
      content-type:
      - application/json
      host:
      - localhost:30001
      user-agent:
      - AsyncOpenAI/Python 1.76.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.76.0
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.12
    method: POST
    uri: http://localhost:30001/chat/completions
  response:
    body:
      string: '{"detail":"Chat completion failed: litellm.APIConnectionError: Invalid
        port: ''generateContent''\nTraceback (most recent call last):\n  File \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/httpx/_urlparse.py\",
        line 364, in normalize_port\n    port_as_int = int(port)\n                  ^^^^^^^^^\nValueError:
        invalid literal for int() with base 10: ''generateContent''\n\nDuring handling
        of the above exception, another exception occurred:\n\nTraceback (most recent
        call last):\n  File \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/litellm/main.py\",
        line 477, in acompletion\n    response = await init_response\n               ^^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py\",
        line 1179, in async_completion\n    response = await client.post(\n               ^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\",
        line 135, in async_wrapper\n    result = await func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py\",
        line 258, in post\n    raise e\n  File \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py\",
        line 208, in post\n    req = self.client.build_request(\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/httpx/_client.py\",
        line 346, in build_request\n    url = self._merge_url(url)\n          ^^^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/httpx/_client.py\",
        line 376, in _merge_url\n    merge_url = URL(url)\n                ^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/httpx/_urls.py\",
        line 117, in __init__\n    self._uri_reference = urlparse(url, **kwargs)\n                          ^^^^^^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/httpx/_urlparse.py\",
        line 260, in urlparse\n    parsed_port: int | None = normalize_port(port,
        scheme)\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/httpx/_urlparse.py\",
        line 366, in normalize_port\n    raise InvalidURL(f\"Invalid port: {port!r}\")\nhttpx.InvalidURL:
        Invalid port: ''generateContent''\n"}'
    headers:
      content-length:
      - '2485'
      content-type:
      - application/json
    status:
      code: 500
      message: Internal Server Error
- request:
    body: '{"messages": [{"role": "user", "content": "Hello, how are you?"}], "model":
      "gemini/gemini-2.0-flash"}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      base_url:
      - http://non.existent.endpoint
      connection:
      - keep-alive
      content-length:
      - '102'
      content-type:
      - application/json
      host:
      - localhost:30001
      user-agent:
      - AsyncOpenAI/Python 1.76.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.76.0
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '1'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.12
    method: POST
    uri: http://localhost:30001/chat/completions
  response:
    body:
      string: '{"detail":"Chat completion failed: litellm.APIConnectionError: Invalid
        port: ''generateContent''\nTraceback (most recent call last):\n  File \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/httpx/_urlparse.py\",
        line 364, in normalize_port\n    port_as_int = int(port)\n                  ^^^^^^^^^\nValueError:
        invalid literal for int() with base 10: ''generateContent''\n\nDuring handling
        of the above exception, another exception occurred:\n\nTraceback (most recent
        call last):\n  File \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/litellm/main.py\",
        line 477, in acompletion\n    response = await init_response\n               ^^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py\",
        line 1179, in async_completion\n    response = await client.post(\n               ^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\",
        line 135, in async_wrapper\n    result = await func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py\",
        line 258, in post\n    raise e\n  File \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py\",
        line 208, in post\n    req = self.client.build_request(\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/httpx/_client.py\",
        line 346, in build_request\n    url = self._merge_url(url)\n          ^^^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/httpx/_client.py\",
        line 376, in _merge_url\n    merge_url = URL(url)\n                ^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/httpx/_urls.py\",
        line 117, in __init__\n    self._uri_reference = urlparse(url, **kwargs)\n                          ^^^^^^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/httpx/_urlparse.py\",
        line 260, in urlparse\n    parsed_port: int | None = normalize_port(port,
        scheme)\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/httpx/_urlparse.py\",
        line 366, in normalize_port\n    raise InvalidURL(f\"Invalid port: {port!r}\")\nhttpx.InvalidURL:
        Invalid port: ''generateContent''\n"}'
    headers:
      content-length:
      - '2485'
      content-type:
      - application/json
    status:
      code: 500
      message: Internal Server Error
- request:
    body: '{"messages": [{"role": "user", "content": "Hello, how are you?"}], "model":
      "gemini/gemini-2.0-flash"}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      base_url:
      - http://non.existent.endpoint
      connection:
      - keep-alive
      content-length:
      - '102'
      content-type:
      - application/json
      host:
      - localhost:30001
      user-agent:
      - AsyncOpenAI/Python 1.76.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.76.0
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '2'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.12
    method: POST
    uri: http://localhost:30001/chat/completions
  response:
    body:
      string: '{"detail":"Chat completion failed: litellm.APIConnectionError: Invalid
        port: ''generateContent''\nTraceback (most recent call last):\n  File \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/httpx/_urlparse.py\",
        line 364, in normalize_port\n    port_as_int = int(port)\n                  ^^^^^^^^^\nValueError:
        invalid literal for int() with base 10: ''generateContent''\n\nDuring handling
        of the above exception, another exception occurred:\n\nTraceback (most recent
        call last):\n  File \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/litellm/main.py\",
        line 477, in acompletion\n    response = await init_response\n               ^^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py\",
        line 1179, in async_completion\n    response = await client.post(\n               ^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/litellm/litellm_core_utils/logging_utils.py\",
        line 135, in async_wrapper\n    result = await func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py\",
        line 258, in post\n    raise e\n  File \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py\",
        line 208, in post\n    req = self.client.build_request(\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/httpx/_client.py\",
        line 346, in build_request\n    url = self._merge_url(url)\n          ^^^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/httpx/_client.py\",
        line 376, in _merge_url\n    merge_url = URL(url)\n                ^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/httpx/_urls.py\",
        line 117, in __init__\n    self._uri_reference = urlparse(url, **kwargs)\n                          ^^^^^^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/httpx/_urlparse.py\",
        line 260, in urlparse\n    parsed_port: int | None = normalize_port(port,
        scheme)\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File
        \"/Users/nik/code/Adala/.venv/lib/python3.11/site-packages/httpx/_urlparse.py\",
        line 366, in normalize_port\n    raise InvalidURL(f\"Invalid port: {port!r}\")\nhttpx.InvalidURL:
        Invalid port: ''generateContent''\n"}'
    headers:
      content-length:
      - '2485'
      content-type:
      - application/json
    status:
      code: 500
      message: Internal Server Error
version: 1
