interactions:
- request:
    body: '{"contents": [{"role": "user", "parts": [{"text": "Hello, how are you?"}]}],
      "generationConfig": {}}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '100'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
      user-agent:
      - litellm/1.65.6
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAC/61STW/TQBC9+1cMe+GSREljGsoFQahKJFALRAgJEJrGY3uV9Y67u6a1ovx3Zp06
        deDKHlareW++3ttdAqA2aDOdYSCvXsF3iQDsujtibAPZIEAfkmCNLjxxD2c3eAsl0ENMUivACjLW
        toB7MmYEoUS7hZYbyNkB+q1Az+CNBwSDriC5bdGgPCrOSBJWkm6fB6CHmpwmuyGgioNm60Eq5ERG
        SngwektQNhVKPOMR3DYBuu55YzeRHmfgOugKjWlBdgZHmLUQWMbw2oc41QTe8z2IIpJbkqm7SQNn
        2L7+YdVgx/3x/XP0pIxjQ3Htbvaevu8JKtdW+/IzoWcbaV/W1zfqiOLv4gMXtePbKO54Opmmi4uL
        dDY/fzmbzqdni3ma9K27pqrxItRHCiju4dEjJSWqOqx5S3bJTefe+aHLwOsTOF084oEDmhPoxXz0
        T1X/TnpqM/wDg+8hy6PRoY0bri+/rdVAoHAyVC9QMtDx7xH/U690cdosefTlYNVXcl4fPCmoEpfG
        Z5PpODfoy66icuRr+XG0yiLHuOUMr6+u3t4tU+svb+pfd03ziVWyT/4A4Brg91IDAAA=
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Mon, 01 Sep 2025 14:41:26 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=552
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Hello, how are you?"}], "model":
      "gemini/gemini-2.0-flash"}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '102'
      content-type:
      - application/json
      host:
      - localhost:30001
      user-agent:
      - AsyncOpenAI/Python 1.102.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.102.0
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.12
    method: POST
    uri: http://localhost:30001/chat/completions
  response:
    body:
      string: '{"id":"chatcmpl-2b0f240b-8fb8-4837-98a5-0fe889f6b656","object":"chat.completion","created":1756737685,"model":"gemini-2.0-flash","choices":[{"finish_reason":"stop","index":0,"message":{"content":"I
        am doing well, thank you for asking! As a large language model, I don''t experience
        emotions or feelings like humans do, but I am functioning optimally and ready
        to assist you. How can I help you today?\n","role":"assistant","tool_calls":null,"function_call":null},"logprobs":-0.047994136810302734}],"usage":{"completion_tokens":47,"prompt_tokens":6,"total_tokens":53,"completion_tokens_details":null,"prompt_tokens_details":{"audio_tokens":null,"cached_tokens":null}},"service_tier":"default"}'
    headers:
      content-length:
      - '691'
      content-type:
      - application/json
    status:
      code: 200
      message: OK
version: 1
