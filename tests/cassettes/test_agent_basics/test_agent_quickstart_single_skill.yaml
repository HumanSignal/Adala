interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "Hey, how''s it going?"}], "model":
      "gpt-3.5-turbo", "max_tokens": 10}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '111'
      content-type:
      - application/json
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//VJDBTsMwEETv+YrFFy5J1aQtgXwAAgRIHBFClZNsE7eO19ibiqrqvyOn
        IYWLDzM7s299jACEqkUBomolV53Vyd2Xvd/vbg/5W717L2ljFT8/de2Bbl70q4hDgsotVvybmlXU
        WY2syJztyqFkDK1pnmWLPE/TdDA6qlGHWGM5WcxWCfeupGSeZqsx2ZKq0IsCPiIAgOPwBkZT47co
        YB7/Kh16LxsUxTQEIBzpoAjpvfIsDYv4YlZkGM2A/YBa0xU8Xnew7T2DhL1y3EsNUzIGT2IMn6at
        mhrrqAyEptd60jfKKN+uHUpPJmzQaBpuzwWnCOBzuK//hyyso87ymmmHJlSmy3OhuPzoH3O8XTCx
        1Bc9W0YjofAHz9itN8o06KxTw7GBMzpFPwAAAP//AwBHUjsG6wEAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab8a613cf83114a-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 22:05:12 GMT
      Server:
      - cloudflare
      Set-Cookie:
      - __cf_bm=kts0B51h555DAKcAuow8W.j36f8XW9elRSxoOSE60Ig-1722377112-1.0.1.1-Yj4IkJD1A48.XUqg22oosi1uoPiZ5.ZlH26O8k3zGsbBoku4TiS_PiSGv8t4ohwiqxTlcSjPPcPDqbx9BtU0Iw;
        path=/; expires=Tue, 30-Jul-24 22:35:12 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=F0NfZvPigR_07YpAxi2E0FGG2NdAFYI8a739MrHcbqM-1722377112236-0.0.1.1-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '475'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49999983'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_040b89af6f9fd068f1d28fc3e29a8b79
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Hey, how''s it going?"}], "model":
      "gpt-3.5-turbo", "max_tokens": 10}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '111'
      content-type:
      - application/json
      cookie:
      - __cf_bm=kts0B51h555DAKcAuow8W.j36f8XW9elRSxoOSE60Ig-1722377112-1.0.1.1-Yj4IkJD1A48.XUqg22oosi1uoPiZ5.ZlH26O8k3zGsbBoku4TiS_PiSGv8t4ohwiqxTlcSjPPcPDqbx9BtU0Iw;
        _cfuvid=F0NfZvPigR_07YpAxi2E0FGG2NdAFYI8a739MrHcbqM-1722377112236-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1SQMW/CMBSE9/yKVy9dAiIBhJq1UmnVqVLFUlXIMQ/H4Pi59otahPjvlUOAdvFw
        5zt/52MGIMxGVCBUI1m13o4evvzTt9Oz93IfH5dvq60uV9NlzZPXg1IiTwmqd6j4khorar1FNuTO
        tgooGVNrsSjL6WJRFGVvtLRBm2La82g6no+4CzWNJkU5H5INGYVRVPCRAQAc+zMxug3+iAom+UVp
        MUapUVTXSwAikE2KkDGayNKxyG+mIsfoeuxntJbu4OW+hV0XGSSkDR1jAB9IB9nmEEkM2dP1UUva
        B6oToOusvepb40xs1gFlJJcesOg0N+eCUwbw2c/r/hELH6j1vGbao0uVxexcKG4f+sccpgsmlvam
        l7NsIBTxEBnb9dY4jcEH029NnNkp+wUAAP//AwBmTMBg6gEAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab8a6182ec3114a-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 22:05:12 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '222'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49999983'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_81b5072078dae0b2fb5bfedaa1ab33fd
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "..."}, {"role": "user", "content":
      "Input: 0 5 0"}], "model": "gpt-3.5-turbo", "max_tokens": 1000, "seed": 47,
      "temperature": 0.0, "tool_choice": {"type": "function", "function": {"name":
      "Output"}}, "tools": [{"type": "function", "function": {"name": "Output", "description":
      "Correctly extracted `Output` with all the required parameters with correct
      types", "parameters": {"properties": {"0_to_1": {"description": "Output:", "title":
      "0 To 1", "type": "string"}}, "required": ["0_to_1"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '557'
      content-type:
      - application/json
      cookie:
      - __cf_bm=kts0B51h555DAKcAuow8W.j36f8XW9elRSxoOSE60Ig-1722377112-1.0.1.1-Yj4IkJD1A48.XUqg22oosi1uoPiZ5.ZlH26O8k3zGsbBoku4TiS_PiSGv8t4ohwiqxTlcSjPPcPDqbx9BtU0Iw;
        _cfuvid=F0NfZvPigR_07YpAxi2E0FGG2NdAFYI8a739MrHcbqM-1722377112236-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//bFLfa9swEH73XyHuOQlWmpDFb6GjbKUQ9rB1bClGkS+OWllSpdPaLuR/
        H7JTOw3Tgzju0/eDOx0yxkBVUDCQe0GycXq8fHY3L7Garf9+veH6yxLXP//IX+7bdf7j/hVGiWG3
        jyjpnTWRtnEaSVnTwdKjIEyqfDGdXi0WnE9boLEV6kSrHY2vJvMxRb+145xP5yfm3iqJAQr2O2OM
        sUN7p4ymwlcoWD567zQYgqgRiv4RY+CtTh0QIahAwhCMBlBaQ2hSbBO1PgPIWl1KofVg3J3DWT0M
        Smhdrm6vt3cxX3HpXh71vVQcq++fV/szv076zbWBdtHIfkBneN8vLswYAyOalruO5CJdMBkD4evY
        oKGUGg4byEuyJd9AsYF8Mt/AET4wjtn/6odTdewHq23tvN2GiznBThkV9qVHEdq8EMi6ziLJPbQL
        jB92As7bxlFJ9glNEvw06+Rg+DIDyE/LBbIk9NBfzrJTPghvgbApd8rU6J1X/TazY/YPAAD//wMA
        bQ31tcwCAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab8a61b4c38114a-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 22:05:14 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '1274'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49998993'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 1ms
      x-request-id:
      - req_d4ae97a63f2d220b7ef0886be004a28b
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "..."}, {"role": "user", "content":
      "Input: 0 0 0"}], "model": "gpt-3.5-turbo", "max_tokens": 1000, "seed": 47,
      "temperature": 0.0, "tool_choice": {"type": "function", "function": {"name":
      "Output"}}, "tools": [{"type": "function", "function": {"name": "Output", "description":
      "Correctly extracted `Output` with all the required parameters with correct
      types", "parameters": {"properties": {"0_to_1": {"description": "Output:", "title":
      "0 To 1", "type": "string"}}, "required": ["0_to_1"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '557'
      content-type:
      - application/json
      cookie:
      - __cf_bm=kts0B51h555DAKcAuow8W.j36f8XW9elRSxoOSE60Ig-1722377112-1.0.1.1-Yj4IkJD1A48.XUqg22oosi1uoPiZ5.ZlH26O8k3zGsbBoku4TiS_PiSGv8t4ohwiqxTlcSjPPcPDqbx9BtU0Iw;
        _cfuvid=F0NfZvPigR_07YpAxi2E0FGG2NdAFYI8a739MrHcbqM-1722377112236-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA2xSS2vjMBC++1eIOSfFzgO3vhWWshS6W2h76aYYWZ443soaVRrTTUP++yI7td1Q
        HcQwn74HMzpEQkBdQiZA7SSrxur51Zu92b/qhx/o1x/Fe4Hq+en+0ZXPD4+2hFlgUPEXFX+yLhQ1
        ViPXZHpYOZSMQTVJF4tlmibJqgMaKlEHWmV5vrxYz7l1Bc3jZLE+MXdUK/SQiT+REEIcujtkNCX+
        g0zEs89Og97LCiEbHgkBjnTogPS+9iwNw2wEFRlGE2KbVusJwEQ6V1Lr0bg/h0k9Dkpqnd8ut9f0
        kd6/38VPxe3d2+XNr+uVTn9O/Hrpve0CbVujhgFN8KGfnZkJAUY2Hfd3y7blM6YQIF3VNmg4pIbD
        BuKcKU82kG0g3sARvrw/Rt/VL6fqOIxVU2UdFf5sSrCtTe13uUPpu7TgmWxvEeReuvW1XzYC1lFj
        OWd6RRMEL1e9HIwfZgKeMCaWemxfLaJTPPB7z9jk29pU6Kyrh1VGx+g/AAAA//8DAH6sKaXJAgAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab8a6250c43114a-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 22:05:14 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '254'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49998993'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 1ms
      x-request-id:
      - req_81cd9aa32ba7d6db6bd0b5f6952dc2ed
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "\nA prompt is a text paragraph that outlines the
      expected actions and instructs the large language model (LLM) to generate a
      specific output. This prompt is concatenated with the input text, and the model
      then creates the required output.\nThis describes the full template how the
      prompt is concatenated with the input to produce the output:\n\n```\n\n{prompt}\nInput:
      {input}\nOutput: {0_to_1}\n```\n\nHere:\n- \"Input: {input}\" is input template,\n-
      \"{prompt}\" is the LLM prompt,\n- \"Output: {0_to_1}\" is the output template.\n\nModel
      can produce erroneous output if a prompt is not well defined. In our collaboration,
      we\u2019ll work together to refine a prompt. The process consists of two main
      steps:\n\n## Step 1\nI will provide you with the current prompt along with prediction
      examples. Each example contains the input text, the final prediction produced
      by the model, and the user feedback. User feedback indicates whether the model
      prediction is correct or not. Your task is to analyze the examples and user
      feedback, determining whether the existing instruction is describing the task
      reflected by these examples precisely, and suggests changes to the prompt to
      address the incorrect predictions.\n\n## Step 2\nNext, you will carefully review
      your reasoning in step 1, integrate the insights to refine the prompt, and provide
      me with the new prompt that improves the model\u2019s performance."}, {"role":
      "assistant", "content": "Sure, I\u2019d be happy to help you with this prompt
      engineering problem. Please provide me with the current prompt and the examples
      with user feedback."}, {"role": "user", "content": "\n## Current prompt\n...\n\n##
      Examples\n### Example #0\n\nInput: 0 5 0\n\nOutput: 0.5\n\nUser feedback: Prediction
      is incorrect. Correct answer: \"1 5 1\"\n\n\n### Example #1\n\nInput: 0 0 0\n\nOutput:
      0\n\nUser feedback: Prediction is incorrect. Correct answer: \"1 1 1\"\n\n\n\nSummarize
      your analysis about incorrect predictions and suggest changes to the prompt."}],
      "model": "gpt-3.5-turbo", "max_tokens": 1000, "seed": 47, "temperature": 0.0}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2186'
      content-type:
      - application/json
      cookie:
      - __cf_bm=kts0B51h555DAKcAuow8W.j36f8XW9elRSxoOSE60Ig-1722377112-1.0.1.1-Yj4IkJD1A48.XUqg22oosi1uoPiZ5.ZlH26O8k3zGsbBoku4TiS_PiSGv8t4ohwiqxTlcSjPPcPDqbx9BtU0Iw;
        _cfuvid=F0NfZvPigR_07YpAxi2E0FGG2NdAFYI8a739MrHcbqM-1722377112236-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//rFTBbhs3EL3rKwZ7loXIjuNYt/QQJECbBIaBAqkKm0uOdllxOTRnGEg1
        /O/BcFeynCJAC/TCA9/M8L03w3mcATTeNStobG/EDimcXT+k939fPGzL7zdffnt/4+TDu5tP7H99
        uP56/dDMNYPav9DKIWthaUgBxVMcYZvRCGrV5dX5+cXV1XJ5WYGBHAZN65KcXSwuz6Tkls5eLc8v
        p8yevEVuVvDHDADgsZ7KMTrcNSt4NT/cDMhsOmxWxyCAJlPQm8YwexYTpZk/g5aiYKy0fzGMDiiC
        9Ai4M8qfIWX65h06MNFVpDBm2CC61tjtHLwAIw4M0hupAVUQeIZIAiU6zPqq87GrsBjegqWc0UrY
        L+D2NAV3Ca2gAyFImDeUB2AaEJiyAG3AmmBLMOorUAbJJrJGTTcjeR9TEYhlaDHzHNoiStNXMa5Y
        ZeLjRAEycgnCi3Vcx1sC41xGVjmewTMXnMNH4NJ1yBq88fGgJGUakijVwWxRn7ABTcb8oxcR0fGp
        JAOc0PqNtzAY6VHpWxOAEuafK1nAO+e8wiaEfbV+8F0v0CL0GNKmhPrI2DEYKCPU/u5EvbIUWbLx
        USqXrmjQScPGF3Ot6Lx64ylWWz5gRrXPQMZvXqdkkj7Z4imuNO7+/n4dH0fsaR0/KvkV3PYZERiF
        tYGTFmBMJuuPgHYPnIxFngMa22tkpW0OTmu6j4KderCOn4vUul/+i5nHyicUdKIPZlXpdRJgQ/kY
        vphEreOtzsMP8nGXgrdewh5YjCD/i8b/HxT103gG7qkEV1v/j26Oc+CKHS8Pw07VO2hPv/rLGWum
        3fB0XCqBupSp1QUUSwjHe/0J3N9lNExRFwgLpTH9aQbwZ11e5cU+akbj7oS2GLXg64ursV7zvC+f
        0eXbAyokJjwDb85fzyaKDe9ZcLjb+NhhTtnXZaZEZ0+z7wAAAP//AwCnoasrywUAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab8a628399b114a-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 22:05:17 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '2636'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49998522'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 1ms
      x-request-id:
      - req_bdda995b707fcaf60504085fba499d62
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "\nA prompt is a text paragraph that outlines the
      expected actions and instructs the large language model (LLM) to generate a
      specific output. This prompt is concatenated with the input text, and the model
      then creates the required output.\nThis describes the full template how the
      prompt is concatenated with the input to produce the output:\n\n```\n\n{prompt}\nInput:
      {input}\nOutput: {0_to_1}\n```\n\nHere:\n- \"Input: {input}\" is input template,\n-
      \"{prompt}\" is the LLM prompt,\n- \"Output: {0_to_1}\" is the output template.\n\nModel
      can produce erroneous output if a prompt is not well defined. In our collaboration,
      we\u2019ll work together to refine a prompt. The process consists of two main
      steps:\n\n## Step 1\nI will provide you with the current prompt along with prediction
      examples. Each example contains the input text, the final prediction produced
      by the model, and the user feedback. User feedback indicates whether the model
      prediction is correct or not. Your task is to analyze the examples and user
      feedback, determining whether the existing instruction is describing the task
      reflected by these examples precisely, and suggests changes to the prompt to
      address the incorrect predictions.\n\n## Step 2\nNext, you will carefully review
      your reasoning in step 1, integrate the insights to refine the prompt, and provide
      me with the new prompt that improves the model\u2019s performance."}, {"role":
      "assistant", "content": "Sure, I\u2019d be happy to help you with this prompt
      engineering problem. Please provide me with the current prompt and the examples
      with user feedback."}, {"role": "user", "content": "\n## Current prompt\n...\n\n##
      Examples\n### Example #0\n\nInput: 0 5 0\n\nOutput: 0.5\n\nUser feedback: Prediction
      is incorrect. Correct answer: \"1 5 1\"\n\n\n### Example #1\n\nInput: 0 0 0\n\nOutput:
      0\n\nUser feedback: Prediction is incorrect. Correct answer: \"1 1 1\"\n\n\n\nSummarize
      your analysis about incorrect predictions and suggest changes to the prompt."},
      {"role": "assistant", "content": "Based on the examples provided and the user
      feedback, it seems that the model is not understanding the task correctly. The
      model is expected to perform some sort of calculation or transformation on the
      input numbers, but it is producing incorrect results.\n\nTo address this issue,
      I suggest refining the prompt to make it clearer that the model needs to perform
      a specific mathematical operation on the input numbers. Additionally, it might
      be helpful to provide more context or constraints to guide the model in the
      right direction.\n\nHere is a revised prompt suggestion:\n\n```\n{prompt}\nInput:
      Three sets of numbers separated by spaces, each set containing three integers.\nOutput:
      Perform a specific mathematical operation on each set of numbers and provide
      the result for each set.\n```\n\nThis revised prompt explicitly states that
      the model needs to perform a mathematical operation on each set of numbers and
      provide the result. This should help guide the model to produce the correct
      output based on the input numbers."}, {"role": "user", "content": "\nNow please
      carefully review your reasoning in Step 1 and help with Step 2: refining the
      prompt.\n\n## Current prompt\n...\n\n## Follow this guidance to refine the prompt:\n\n1.
      The new prompt should should describe the task precisely, and address the points
      raised in the user feedback.\n\n2. The new prompt should be similar to the current
      prompt, and only differ in the parts that address the issues you identified
      in Step 1.\n    Example:\n    - Current prompt: \"Generate a summary of the
      input text.\"\n    - New prompt: \"Generate a summary of the input text. Pay
      attention to the original style.\"\n\n3. Reply only with the new prompt. Do
      not include input and output templates in the prompt.\n"}], "model": "gpt-3.5-turbo",
      "max_tokens": 1000, "seed": 47, "temperature": 0.0}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '3990'
      content-type:
      - application/json
      cookie:
      - __cf_bm=kts0B51h555DAKcAuow8W.j36f8XW9elRSxoOSE60Ig-1722377112-1.0.1.1-Yj4IkJD1A48.XUqg22oosi1uoPiZ5.ZlH26O8k3zGsbBoku4TiS_PiSGv8t4ohwiqxTlcSjPPcPDqbx9BtU0Iw;
        _cfuvid=F0NfZvPigR_07YpAxi2E0FGG2NdAFYI8a739MrHcbqM-1722377112236-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA3RSQW7bMBC86xULnm0jsmHI9bVI0gI5uM2lQF0YFLWS2FJchrsMGgT+e0HJlpFD
        L4Qww5kd7fC9AFC2UXtQptdihuCWn17C4/oBE94/Hb7+qJ8Pry/f4sOXx/7Jfe7UIiuo/o1GrqqV
        oSE4FEt+ok1ELZhdy2q93lRVWe5GYqAGXZZ1QZab1XYpKda0vCvX24uyJ2uQ1R5+FgAA7+OZM/oG
        /6o93C2uyIDMukO1ny8BqEguI0ozWxbtRS1upCEv6MfY37G1HkF6hBBpCAJCoJsmIvOIWuaEDLZB
        L7a12ID18CwYoNwf/dEf1QFjS3EADRzQ2NYaGLT0OGixRjuggFHnnQB5QG16YBSgFnwaaoycB7/a
        ZnIeR/qQZAHaN0BJQpIRjcjJCbQUZ5MV3HtOcYr/n5mWQYfgcnBDMaIR95b/sUOfryBoY9L4MQ1g
        qDVjk7POWa5JV0elLls8z+t31IVIda7KJ+dmvLXecn+KqJl8XjULhUl+LgB+jTWnD82pqYKT0B/0
        2bCqdpOfur2sG7vdXkgh0e6G7zab4pJQ8RsLDqfW+g5jiHZsPecszsU/AAAA//8DALkExNT0AgAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab8a63a4e48114a-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 22:05:18 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '951'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49998095'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 2ms
      x-request-id:
      - req_797c880bfcb20368303982a6c698589c
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "Refine the prompt to address
      the issues identified in Step 1:\n\n\"Perform a specific mathematical operation
      on each set of numbers provided in the input, and output the result for each
      set. Ensure the mathematical operation is applied correctly to generate accurate
      results based on the input numbers.\""}, {"role": "user", "content": "Input:
      0 5 0"}], "model": "gpt-3.5-turbo", "max_tokens": 1000, "seed": 47, "temperature":
      0.0, "tool_choice": {"type": "function", "function": {"name": "Output"}}, "tools":
      [{"type": "function", "function": {"name": "Output", "description": "Correctly
      extracted `Output` with all the required parameters with correct types", "parameters":
      {"properties": {"0_to_1": {"description": "Output:", "title": "0 To 1", "type":
      "string"}}, "required": ["0_to_1"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '858'
      content-type:
      - application/json
      cookie:
      - __cf_bm=kts0B51h555DAKcAuow8W.j36f8XW9elRSxoOSE60Ig-1722377112-1.0.1.1-Yj4IkJD1A48.XUqg22oosi1uoPiZ5.ZlH26O8k3zGsbBoku4TiS_PiSGv8t4ohwiqxTlcSjPPcPDqbx9BtU0Iw;
        _cfuvid=F0NfZvPigR_07YpAxi2E0FGG2NdAFYI8a739MrHcbqM-1722377112236-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA2xS30/bMBB+z19h3XOLmoa2a96KBAgQKxuCaawoclwnDXN8rn2RBlX/d+SkTUI1
        P1in+/z90J13AWNQrCFmIDacRGnUcL4119H38W2avV08Vj9u7q/vXn7r5fPD1tynMPAMTN+koCPr
        TGBplKQCdQMLKzlJrxrOxuNoNgvDeQ2UuJbK03JDw+hsMqTKpjgchePJgbnBQkgHMfsTMMbYrr59
        Rr2W/yBmo8GxU0rneC4hbh8xBhaV7wB3rnDENcGgAwVqktrH1pVSPYAQVSK4Up1xc3a9uhsUVypZ
        3PIr/bJQ+Tp7usyWHz9/2WluHqKeXyP9bupAWaVFO6Ae3vbjEzPGQPOy5i4rMhWdMBkDbvOqlJp8
        atitYJQQJuEK4hVMVrCHL+/3wf/q10O1b8eqMDcWU3cyJcgKXbhNYiV3dVpwhKax8HKv9fqqLxsB
        Y7E0lBD+ldoLhtG3Rg+6H9OhR4yQuOqRzqfBISC4d0eyTLJC59IaW7TLDPbBJwAAAP//AwDstEkN
        ywIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab8a6429d75114a-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 22:05:19 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '223'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49998920'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 1ms
      x-request-id:
      - req_821f1b294f972e3fe269debbc2688016
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "Refine the prompt to address
      the issues identified in Step 1:\n\n\"Perform a specific mathematical operation
      on each set of numbers provided in the input, and output the result for each
      set. Ensure the mathematical operation is applied correctly to generate accurate
      results based on the input numbers.\""}, {"role": "user", "content": "Input:
      0 0 0"}], "model": "gpt-3.5-turbo", "max_tokens": 1000, "seed": 47, "temperature":
      0.0, "tool_choice": {"type": "function", "function": {"name": "Output"}}, "tools":
      [{"type": "function", "function": {"name": "Output", "description": "Correctly
      extracted `Output` with all the required parameters with correct types", "parameters":
      {"properties": {"0_to_1": {"description": "Output:", "title": "0 To 1", "type":
      "string"}}, "required": ["0_to_1"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '858'
      content-type:
      - application/json
      cookie:
      - __cf_bm=kts0B51h555DAKcAuow8W.j36f8XW9elRSxoOSE60Ig-1722377112-1.0.1.1-Yj4IkJD1A48.XUqg22oosi1uoPiZ5.ZlH26O8k3zGsbBoku4TiS_PiSGv8t4ohwiqxTlcSjPPcPDqbx9BtU0Iw;
        _cfuvid=F0NfZvPigR_07YpAxi2E0FGG2NdAFYI8a739MrHcbqM-1722377112236-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA2xS22rjMBB991eIeU5KHLe5+K0LpexS0i6ULsumGFlRHLWSRiuNIW3Ivy+yE9sN
        qwcxzNG5MKNDwhioDeQMxI6TME6Pl3/dffb0sni+syvHX/bT7dvTvVmpxbdZ9gNGkYHlmxR0Zl0J
        NE5LUmhbWHjJSUbVdD6dZvN5mi4bwOBG6kirHI2zq5sx1b7E8SSd3pyYO1RCBsjZn4Qxxg7NHTPa
        jdxDziajc8fIEHglIe8eMQYedewAD0EF4pZg1IMCLUkbY9ta6wFAiLoQXOveuD2HQd0Pimtd/LLl
        Z7ma3f7OfuqHu3qxr5bh/fvj7cCvlf5wTaBtbUU3oAHe9fMLM8bActNwH2tyNV0wGQPuq9pISzE1
        HNYwKQiLdA35GiZrOMKX98fkf/XrqTp2Y9VYOY9luJgSbJVVYVd4yUOTFgKhay2i3GuzvvrLRsB5
        NI4Kwndpo2CaLVo96H9Mj54xQuJ6QLqeJaeAED4CSVNsla2kd151y0yOyT8AAAD//wMA2x2yxssC
        AAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab8a6459b83114a-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 22:05:20 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '227'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49998920'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 1ms
      x-request-id:
      - req_9e7e5f5e838bf68d91b691546ef8a4b0
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "\nA prompt is a text paragraph that outlines the
      expected actions and instructs the large language model (LLM) to generate a
      specific output. This prompt is concatenated with the input text, and the model
      then creates the required output.\nThis describes the full template how the
      prompt is concatenated with the input to produce the output:\n\n```\n\n{prompt}\nInput:
      {input}\nOutput: {0_to_1}\n```\n\nHere:\n- \"Input: {input}\" is input template,\n-
      \"{prompt}\" is the LLM prompt,\n- \"Output: {0_to_1}\" is the output template.\n\nModel
      can produce erroneous output if a prompt is not well defined. In our collaboration,
      we\u2019ll work together to refine a prompt. The process consists of two main
      steps:\n\n## Step 1\nI will provide you with the current prompt along with prediction
      examples. Each example contains the input text, the final prediction produced
      by the model, and the user feedback. User feedback indicates whether the model
      prediction is correct or not. Your task is to analyze the examples and user
      feedback, determining whether the existing instruction is describing the task
      reflected by these examples precisely, and suggests changes to the prompt to
      address the incorrect predictions.\n\n## Step 2\nNext, you will carefully review
      your reasoning in step 1, integrate the insights to refine the prompt, and provide
      me with the new prompt that improves the model\u2019s performance."}, {"role":
      "assistant", "content": "Sure, I\u2019d be happy to help you with this prompt
      engineering problem. Please provide me with the current prompt and the examples
      with user feedback."}, {"role": "user", "content": "\n## Current prompt\nRefine
      the prompt to address the issues identified in Step 1:\n\n\"Perform a specific
      mathematical operation on each set of numbers provided in the input, and output
      the result for each set. Ensure the mathematical operation is applied correctly
      to generate accurate results based on the input numbers.\"\n\n## Examples\n###
      Example #0\n\nInput: 0 5 0\n\nOutput: 5\n\nUser feedback: Prediction is incorrect.
      Correct answer: \"1 5 1\"\n\n\n### Example #1\n\nInput: 0 0 0\n\nOutput: 0\n\nUser
      feedback: Prediction is incorrect. Correct answer: \"1 1 1\"\n\n\n\nSummarize
      your analysis about incorrect predictions and suggest changes to the prompt."}],
      "model": "gpt-3.5-turbo", "max_tokens": 1000, "seed": 47, "temperature": 0.0}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2485'
      content-type:
      - application/json
      cookie:
      - __cf_bm=kts0B51h555DAKcAuow8W.j36f8XW9elRSxoOSE60Ig-1722377112-1.0.1.1-Yj4IkJD1A48.XUqg22oosi1uoPiZ5.ZlH26O8k3zGsbBoku4TiS_PiSGv8t4ohwiqxTlcSjPPcPDqbx9BtU0Iw;
        _cfuvid=F0NfZvPigR_07YpAxi2E0FGG2NdAFYI8a739MrHcbqM-1722377112236-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA5RUS28UMQy+76+whgtI21V3eZTuEQkhuPDqpWJRlU08M2mTOMQO7YL631EyszMF
        ISEuOdifnc+fHz8XAI01zRYa3SvRPrqT82/xzbPPlx8vLs/1y8t39OP02l+cX3963/nvN82yRND+
        GrUco1aafHQolsLg1gmVYMm6Pttsnp6drTen1eHJoCthXZSTp6vnJ5LTnk5O15vnY2RPViM3W/iy
        AAD4Wd/CMRi8a7ZQ81SLR2bVYbOdQABNIlcsjWK2LCpIs5ydmoJgqLRfKUYDFEB6BLxThT9DTPTd
        GjSggqmezJigRTR7pW+WYAUY0TNIr6QCdE4Jg5RIHwUsQyABpXVOStAdoMvW2NBVcK0ehCBiain5
        IQOlhFrAK+nRK7FaOaCISRU9jxRtiFkgZL/HxCu4qKZjaExorC5wBs5dhywzw+FTrw6V2b7ECaaY
        UI60Ru5jNncASg/xKkZ3mEr4O0vFgHcRtaBZ7cIuXBAoYxIyD+yZMzJYg0Fsa9GAPZb1lxqW8HYq
        I2Frwx9EFUNLztEtb8tfjx7Bp4JCAx8qYBd2zYdRYWWMPeqISvfAKEDtUcm54/aBzsvaf8pSNC9W
        zh5aSlOGFbwOnBPOKs//TJpYrtKVamdphaDDUCA4TQkk5OyEYf9wKH/v+K4ppb46AEfUtv1XPx4f
        +TwpfXFW2/L5WOMg4xJuEZT1dR4HFUA7VAlTHVoVNBbfPEMUoKfbEa+n3v45mZaHrqEvi8E9ZWeg
        RxcfpNqjCCbIwWAqazpsmyi+qdLHRCbrAk7/J1MzLvv9dCUcdTHRvlyUkJ2b7GWsuL9KqJhCuQgs
        FIfw+wXA13qN8m8HphmEuxK6wVASPnt5PuRr5gM4e9dnm9ErJMrNjhcv1ouRYsMHFvRXrQ1dWUpb
        r1Mhurhf/AIAAP//AwAUjdf1nAUAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab8a648c8b9114a-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 22:05:23 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '2746'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49998448'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 1ms
      x-request-id:
      - req_cab39a43b1d6f8568bc85df848ea57e6
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "\nA prompt is a text paragraph that outlines the
      expected actions and instructs the large language model (LLM) to generate a
      specific output. This prompt is concatenated with the input text, and the model
      then creates the required output.\nThis describes the full template how the
      prompt is concatenated with the input to produce the output:\n\n```\n\n{prompt}\nInput:
      {input}\nOutput: {0_to_1}\n```\n\nHere:\n- \"Input: {input}\" is input template,\n-
      \"{prompt}\" is the LLM prompt,\n- \"Output: {0_to_1}\" is the output template.\n\nModel
      can produce erroneous output if a prompt is not well defined. In our collaboration,
      we\u2019ll work together to refine a prompt. The process consists of two main
      steps:\n\n## Step 1\nI will provide you with the current prompt along with prediction
      examples. Each example contains the input text, the final prediction produced
      by the model, and the user feedback. User feedback indicates whether the model
      prediction is correct or not. Your task is to analyze the examples and user
      feedback, determining whether the existing instruction is describing the task
      reflected by these examples precisely, and suggests changes to the prompt to
      address the incorrect predictions.\n\n## Step 2\nNext, you will carefully review
      your reasoning in step 1, integrate the insights to refine the prompt, and provide
      me with the new prompt that improves the model\u2019s performance."}, {"role":
      "assistant", "content": "Sure, I\u2019d be happy to help you with this prompt
      engineering problem. Please provide me with the current prompt and the examples
      with user feedback."}, {"role": "user", "content": "\n## Current prompt\nRefine
      the prompt to address the issues identified in Step 1:\n\n\"Perform a specific
      mathematical operation on each set of numbers provided in the input, and output
      the result for each set. Ensure the mathematical operation is applied correctly
      to generate accurate results based on the input numbers.\"\n\n## Examples\n###
      Example #0\n\nInput: 0 5 0\n\nOutput: 5\n\nUser feedback: Prediction is incorrect.
      Correct answer: \"1 5 1\"\n\n\n### Example #1\n\nInput: 0 0 0\n\nOutput: 0\n\nUser
      feedback: Prediction is incorrect. Correct answer: \"1 1 1\"\n\n\n\nSummarize
      your analysis about incorrect predictions and suggest changes to the prompt."},
      {"role": "assistant", "content": "Based on the examples provided and the user
      feedback, it seems that the current prompt is not accurately guiding the model
      to perform the correct mathematical operation on the input numbers. The incorrect
      predictions suggest that the model may not be interpreting the prompt correctly
      or may not be applying the mathematical operation as expected.\n\nTo address
      the issues identified in the incorrect predictions, I suggest refining the prompt
      as follows:\n\n## Refined Prompt\n\"Perform addition on each set of numbers
      provided in the input, and output the sum for each set. Ensure that the addition
      operation is applied correctly to generate accurate results based on the input
      numbers.\"\n\nBy specifying the mathematical operation (addition) explicitly
      in the prompt, we aim to provide clearer guidance to the model on how to process
      the input numbers. This refinement should help the model better understand the
      task and produce more accurate results based on the input numbers."}, {"role":
      "user", "content": "\nNow please carefully review your reasoning in Step 1 and
      help with Step 2: refining the prompt.\n\n## Current prompt\nRefine the prompt
      to address the issues identified in Step 1:\n\n\"Perform a specific mathematical
      operation on each set of numbers provided in the input, and output the result
      for each set. Ensure the mathematical operation is applied correctly to generate
      accurate results based on the input numbers.\"\n\n## Follow this guidance to
      refine the prompt:\n\n1. The new prompt should should describe the task precisely,
      and address the points raised in the user feedback.\n\n2. The new prompt should
      be similar to the current prompt, and only differ in the parts that address
      the issues you identified in Step 1.\n    Example:\n    - Current prompt: \"Generate
      a summary of the input text.\"\n    - New prompt: \"Generate a summary of the
      input text. Pay attention to the original style.\"\n\n3. Reply only with the
      new prompt. Do not include input and output templates in the prompt.\n"}], "model":
      "gpt-3.5-turbo", "max_tokens": 1000, "seed": 47, "temperature": 0.0}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '4543'
      content-type:
      - application/json
      cookie:
      - __cf_bm=kts0B51h555DAKcAuow8W.j36f8XW9elRSxoOSE60Ig-1722377112-1.0.1.1-Yj4IkJD1A48.XUqg22oosi1uoPiZ5.ZlH26O8k3zGsbBoku4TiS_PiSGv8t4ohwiqxTlcSjPPcPDqbx9BtU0Iw;
        _cfuvid=F0NfZvPigR_07YpAxi2E0FGG2NdAFYI8a739MrHcbqM-1722377112236-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1RSXYvbMBB8969Y9JyEi9M0Fz+3HD0K/YKGcilBkdaOWlmr065KjyP/vchOYvoi
        lpmd0WhXrxWAclY1oMxJi+mjn2+f48Pm8f75xxd690GW8eObnf30+H3T7Xb+Qc2Kgo6/0MhVtTDU
        R4/iKIy0SagFi+tyU9erzWZZrwaiJ4u+yLoo89ViPZecjjS/W9bri/JEziCrBp4qAIDX4SwZg8W/
        qoG72RXpkVl3qJpbE4BK5AuiNLNj0UHUbCINBcEwxP6KrQsIckKIifooIATa2oTMA+qYMzI4i0Fc
        69CCC/BNMMKy2Yd92KvPmFpKfVG58nSgAKjNCRgFqIWQ+yMmLv5/nB0NBucQs8xABwuUJWYZUM49
        tJRuDgt4HzinElGPHdM9EZMeKsegY/QlnaGU0Ih/KQ/pMJQWBG1MHoqEnL0wHDWjLUlvSa45F3ul
        LqM632bsqYuJjmUfIXt/w1sXHJ8OCTVTKPNkoTjKzxXAz2GX+b/1qHHOB6HfGIrh/dvt6Kem7zOx
        69WFFBLtJ3xb19UloeIXFuwPrQsdppjcsNqSszpX/wAAAP//AwC47pjH2QIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab8a65bfe52114a-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 22:05:24 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '709'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49997958'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 2ms
      x-request-id:
      - req_92ecac03cf54a8419ef413c15accd3f2
    status:
      code: 200
      message: OK
version: 1
