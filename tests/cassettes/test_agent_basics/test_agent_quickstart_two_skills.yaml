interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "Hey, how''s it going?"}], "model":
      "gpt-4o-mini", "max_tokens": 10}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '109'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1RQy2rDMBC8+ysWXXqJi+04pM0xlNAnhbaHQilGlte2Ur0qraEh5N+LnFd72cPM
        zuzMbhMAJhu2ACZ6TkI7lV5/d3r5ulndPL51/vbN1/cFiYfV/P15+fTCJlFh6zUKOqouhdVOIUlr
        9rTwyAmjaz4vimlZzvLZSGjboIqyzlFa2lRLI9MiK8o0m6f51UHdWykwsAV8JAAA23HGnKbBH7aA
        bHJENIbAO2SL0xIA81ZFhPEQZCBuiE3OpLCG0IzR7y40rIdAwMF523muJ1APBBHv0SNw04BH3mzY
        Qb87HVa2c97WMaQZlDrhrTQy9JVHHqyJRxSajvq9wS4B+BwrDv9SM+etdlSR/UITLfNyb8jOj/1D
        HuozssTVGS/K5JCQhU0g1FUrTYfeebnv27oqa7NpU7YZIkt2yS8AAAD//wMAwd/NJf0BAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58a475807291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:01:56 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '240'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149999984'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_773ebc194d528ba11cb62d6f0f9190f5
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Hey, how''s it going?"}], "model":
      "gpt-3.5-turbo", "max_tokens": 10}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '111'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//VJA7U8MwEIR7/4pDDY2dsR0bgksYXgUVVDwmIysXW0HSGes8A5PJf2fk
        OAk0Kna1q2+1jQCEXokKhGolK9uZ5OqrsTdKX9/e3S+KJ3wtvZL1c7pI9cscRRwSVG9Q8SE1U2Q7
        g6zJ7W3Vo2QMrdllns+LoswuRsPSCk2INR0n81mZ8NDXlKRZXk7JlrRCLyp4iwAAtuMZGN0Kv0UF
        aXxQLHovGxTV8RKA6MkERUjvtWfpWMQnU5FjdCP2u3tAY+gMHs8tbAbPICFMqYljMSV2x6cMNV1P
        dcBygzFHfa2d9u2yR+nJhVqDruF2X7CLAD7GUcM/TtH1ZDteMn2iC5VZsS8Up2/8Y06DBRNLc9Lz
        IpoIhf/xjHa51q7Bvuv1uDBwRrvoFwAA//8DANeV2NbgAQAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58a4aab25291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:01:56 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '206'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '50000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '49999983'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_29a3d5265b082504114f45805ea856a2
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "..."}, {"role": "user", "content":
      "Text: 0 5 0"}], "model": "gpt-4o-mini", "max_tokens": 1000, "seed": 47, "temperature":
      0.0, "tool_choice": {"type": "function", "function": {"name": "Output"}}, "tools":
      [{"type": "function", "function": {"name": "Output", "description": "Correctly
      extracted `Output` with all the required parameters with correct types", "parameters":
      {"properties": {"0->1": {"description": "Output:", "title": "0->1", "type":
      "string"}}, "required": ["0->1"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '548'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//bFJLT+MwEL7nV1hzJiunTSnNgQusVrssrUBdpBVFkXGd1OAX9kSiqvrf
        kZPQlAofrNF8/h6a8S4hBOQaCgJ8w5Brp9LZW62v75cP53M2n7xtf6lztrj9mc3/vvAxwllk2OcX
        wfGT9YNb7ZRAaU0Hcy8YiqiaTUejcZ5PsmkLaLsWKtJqh2luUy2NTEd0lKd0mmYXPXtjJRcBCvKY
        EELIrr1jTrMW71AQevbZ0SIEVgsoDo8IAW9V7AALQQZkpsvcg9waFCZGN41SRwBaq0rOlBqMu7M7
        qodhMaXKGb/b/L+g/6rF7fuf8c0y3F8/XPnfd0d+nfTWtYGqxvDDkI7wQ784MSMEDNMtd9Gga/CE
        SQgwXzdaGIypYbcCml5mKyhWQMmE0BXs4Qtjn3xXP/XV/jBYZWvn7XM4mRNU0siwKb1goc0LAa3r
        LKLcU7vA5stOwHmrHZZoX4WJgtNZJwfDtxnALOtBtMjU0J/RpM8HYRtQ6LKSphbeedluEypX0oqO
        13lFhYBkn3wAAAD//wMA1xSIoNsCAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58a4dbebd291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:01:57 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '208'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149998994'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_8e1b1aed1bb4d7ffbe657d283359f5bc
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "..."}, {"role": "user", "content":
      "Text: 0 0 0"}], "model": "gpt-4o-mini", "max_tokens": 1000, "seed": 47, "temperature":
      0.0, "tool_choice": {"type": "function", "function": {"name": "Output"}}, "tools":
      [{"type": "function", "function": {"name": "Output", "description": "Correctly
      extracted `Output` with all the required parameters with correct types", "parameters":
      {"properties": {"0->1": {"description": "Output:", "title": "0->1", "type":
      "string"}}, "required": ["0->1"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '548'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//bFLda9swEH/3X3HcczzkxF0aP+xhrHQLlLQUOrqlGFWRHaX6qnXOVkL+
        9yE7jdMwPYjjfvp9cKddAoBqhQWgWHMSxut09lqbb9fcVfXNXf198/KZ3VxdPG70rbmaKBxFhnve
        SEHvrE/CGa8lKWd7WDSSk4yq2XQ8nuT5RTbtAONWUkda7SnNXWqUVemYjfOUTdPs8sBeOyVkwAJ+
        JwAAu+6OOe1K/sUC2Oi9Y2QIvJZYHB8BYON07CAPQQXilnA0gMJZkjZGt63WJwA5p0vBtR6M+7M7
        qYdhca3L++yPXy9etw+P178W8x/byfw+/Py6nZ/49dJvvgtUtVYch3SCH/vFmRkAWm467qIl39IZ
        EwB5U7dGWoqpcbdEln7JllgskQEDtsQ9fmDsk//VT4dqfxysdrVv3HM4mxNWyqqwLhvJQ5cXAznf
        W0S5p26B7YedoG+c8VSSe5E2Ck5nvRwO32YAs+wAkiOuh/6MJYd8GN4CSVNWytay8Y3qtomVL1nF
        Jqu8YlJisk/+AQAA//8DAF6jBrbbAgAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58a549d96291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:01:58 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '273'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149998994'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_c3285623f0e917f3bcb19680bf3d1481
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "..."}, {"role": "user", "content":
      "Text: 0 5 0"}], "model": "gpt-4o-mini", "max_tokens": 1000, "seed": 47, "temperature":
      0.0, "tool_choice": {"type": "function", "function": {"name": "Output"}}, "tools":
      [{"type": "function", "function": {"name": "Output", "description": "Correctly
      extracted `Output` with all the required parameters with correct types", "parameters":
      {"properties": {"1->2": {"description": "Output:", "title": "1->2", "type":
      "string"}}, "required": ["1->2"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '548'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA2xSS2vjMBC++1eIOcdFdmyc+LCwbLqwe9geSntoU4yiyI5avSqNl4aQ/77ITuM0
        rA5imE/fgxkdEkJAbqEmwHcMuXYqXb53+vYPynzRPZb79/Bklh+/+1/m74N6vINZZNjNq+D4ybrh
        VjslUFozwtwLhiKqZlWez4uizBYDoO1WqEjrHKaFTbU0Ms1pXqS0SrPFib2zkosANXlOCCHkMNwx
        p9mKD6gJnX12tAiBdQLq8yNCwFsVO8BCkAGZQZhNILcGhYnRTa/UBYDWqoYzpSbj8Rwu6mlYTKkG
        N983ZfV6/1DOf/5487eVWLEVK1cXfqP03g2B2t7w85Au8HO/vjIjBAzTA/euR9fjFZMQYL7rtTAY
        U8NhDVn6LV9DvQZKSkLXcIQvjGPyv/rlVB3Pg1W2c95uwtWcoJVGhl3jBQtDXgho3WgR5V6GBfZf
        dgLOW+2wQfsmTBSslqMcTN9mArPsBKJFpqb+kianfBD2AYVuWmk64Z2XwzahdQ1t6XxbtFQISI7J
        PwAAAP//AwBRRkeW2wIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58a57d8d2291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:01:59 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '343'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149998994'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_6503764053db6fa86772f7b227bfe01f
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "..."}, {"role": "user", "content":
      "Text: 0 0 0"}], "model": "gpt-4o-mini", "max_tokens": 1000, "seed": 47, "temperature":
      0.0, "tool_choice": {"type": "function", "function": {"name": "Output"}}, "tools":
      [{"type": "function", "function": {"name": "Output", "description": "Correctly
      extracted `Output` with all the required parameters with correct types", "parameters":
      {"properties": {"1->2": {"description": "Output:", "title": "1->2", "type":
      "string"}}, "required": ["1->2"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '548'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA2xSz2/bIBS++69A7xxX2PGaxYdJXaVuSyJlh2mHLZVFCLZpgUcBq+2i/O8Vdhqn
        0Tigp/fx/dB77BNCQO6gJMBbFri2Kp0/NfpuOX34Xi9vrXnE+m6LbXurFsvnbw1MIgO3D4KHd9YV
        R22VCBLNAHMnWBBRNZvl+bQoPmXzHtC4EyrSGhvSAlMtjUxzmhcpnaXZ5yO7RcmFh5L8TQghZN/f
        MafZiRcoCZ28d7TwnjUCytMjQsChih1g3ksfmAkwGUGOJggTo5tOqTMgIKqKM6VG4+Hsz+pxWEyp
        avGDNu7r6jdf3fz8c7N++fXPrq4X6+7Mb5B+tX2gujP8NKQz/NQvL8wIAcN0z113wXbhgkkIMNd0
        WpgQU8N+A1n6Jd9AuQFKKKEbOMAHxiH5X31/rA6nwSpsrMOtv5gT1NJI31ZOMN/nBR/QDhZR7r5f
        YPdhJ2AdahuqgI/CRMHZfJCD8duMYJYdwYCBqbE/p8kxH/hXH4Suamka4ayT/TahthWt6XRX1FQI
        SA7JGwAAAP//AwBeqCna2wIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58a5ccd83291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:01:59 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '247'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149998994'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_4651b326f40ff10b9a703973c5119774
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "\nA prompt is a text paragraph that outlines the
      expected actions and instructs the large language model (LLM) to generate a
      specific output. This prompt is concatenated with the input text, and the model
      then creates the required output.\nThis describes the full template how the
      prompt is concatenated with the input to produce the output:\n\n```\n\n{prompt}\nText:
      {input}\nOutput: {0->1}\n```\n\nHere:\n- \"Text: {input}\" is input template,\n-
      \"{prompt}\" is the LLM prompt,\n- \"Output: {0->1}\" is the output template.\n\nModel
      can produce erroneous output if a prompt is not well defined. In our collaboration,
      we\u2019ll work together to refine a prompt. The process consists of two main
      steps:\n\n## Step 1\nI will provide you with the current prompt along with prediction
      examples. Each example contains the input text, the final prediction produced
      by the model, and the user feedback. User feedback indicates whether the model
      prediction is correct or not. Your task is to analyze the examples and user
      feedback, determining whether the existing instruction is describing the task
      reflected by these examples precisely, and suggests changes to the prompt to
      address the incorrect predictions.\n\n## Step 2\nNext, you will carefully review
      your reasoning in step 1, integrate the insights to refine the prompt, and provide
      me with the new prompt that improves the model\u2019s performance."}, {"role":
      "assistant", "content": "Sure, I\u2019d be happy to help you with this prompt
      engineering problem. Please provide me with the current prompt and the examples
      with user feedback."}, {"role": "user", "content": "\n## Current prompt\n...\n\n##
      Examples\n### Example #0\n\nText: 0 5 0\n\nOutput: 0 5 0\n\nUser feedback: Prediction
      is incorrect. Correct answer: \"1 5 1\"\n\n\n### Example #1\n\nText: 0 0 0\n\nOutput:
      0 0 0\n\nUser feedback: Prediction is incorrect. Correct answer: \"1 1 1\"\n\n\n\nSummarize
      your analysis about incorrect predictions and suggest changes to the prompt."}],
      "model": "gpt-4o-mini", "max_tokens": 1000, "seed": 47, "temperature": 0.0}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2182'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//zFbLbus2EN37KwbK4gKGZUiO05t6UaAI8lrc5gLxrioSmhpJTKghS1J+
        IAhwf6O/1y8pSEm2nAfaZTc2wJnhzDlzZqiXEUAk8mgBEa+Y47WW8c9/lvX1pebz9dPN3bqR35bz
        q+ub84v7p8vrs2jiI9TqCbnro6Zc1VqiE4paMzfIHPpb06+z2el8fjZLgqFWOUofVmoXz1VcCxLx
        LJnN4+RrnJ530ZUSHG20gN9HAAAv4dfXSTluowWEu8JJjdayEqPF3gkgMkr6k4hZK6xj5KLJwcgV
        OaRQ+snJCfxKTO6ssKAKuCWujEHu4LvBXHCPx2aUUTqF8fhyyzxIOEnG40VGABDDeHxLunHj8QKy
        KIEzSLJob/rmscJd4z71uOjSDX1SOIN04HOFmK8Yf/bWZYUQGPxiQYUYyEUOpBzwilGJ4CoE4UuC
        NZMNWmAWcKuRO8ynIb6H2MXbpizROguuYi6EhwRgK9XIHFYIzjCyhTK1oHJwvyBgYDVyUQgOG7ab
        gBTPKHew2oEgbrBGcj6Go3FMUFfR1BM6OyI0/ZTQ5F8JTf4DoemnhN6LWkhmwCk4tHcyoKFgQmLu
        7XsaDhx8SKigXHDmsGOUSdm34kDpnh7MoTCqhsRnSAM1XpR3K4tmzTr9xYe+g7Ch2xrNsCN9hw9F
        hlhQ9E4QU7gl65DlXvC1ykWxO+rrBITzWayotdwB+lmk0h96zqZ9NcegbS8jYKCZc2gINhUa/FBQ
        R+LwDh0/gobU3nfSYlLuQlEWsW5JDWKJ4bYYoPNjzQRZL4osagPeS7htZRalWTRtLzlQW7MdELYe
        THvwzN/qVwiSe0utaSQGTymBmnqF5g2Avpf3LTOYw0UYURvEVCF8N6rWLqOlAlFro9YDtr7YvsWM
        OLaC1MG/R8UlMiP9pFlnGj4c3UH9b4ruMh/r4QYN/v3jLwsMDBaCMIc1Ghv0UwwyLzyiOI7933j8
        G246BGF4s2j5fj72xLzdCMh41Rm9LZ32vezOhIVk0q804drh8OnWIm9ZGna0Gzxmw0JiHGOLmhn/
        AIF1RlA59eO/L9535UoQkx0AuA8MNgYzenx8zOj/DYWWuHULeAl1vWbU7roFvCTxL+lrByGjZeV3
        BW563eBWS8GFkzuwrttP+JGqJ7CpBK96oVUo9UBcJRL6esLR2y2wYtaDoF41HmMO2G5WO426V/h1
        /3xLVWqjVv6pp0bK/XkhSNjqwSCzivxTbZ3SbfjrCOCP8JnQHL38UYvzwalnJH/hfH7a3hcdvk4+
        sjrlmDwYzs9/GnUlRnZnHdYPhaASjTai/Wwo9ENSJKf5vEgQo9Hr6B8AAAD//wMAFs5PZkQJAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58a6179e6291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:02:07 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '6908'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149998524'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_dec0a907edc7ba95edfc0b31b84b80bd
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "\nA prompt is a text paragraph that outlines the
      expected actions and instructs the large language model (LLM) to generate a
      specific output. This prompt is concatenated with the input text, and the model
      then creates the required output.\nThis describes the full template how the
      prompt is concatenated with the input to produce the output:\n\n```\n\n{prompt}\nText:
      {input}\nOutput: {0->1}\n```\n\nHere:\n- \"Text: {input}\" is input template,\n-
      \"{prompt}\" is the LLM prompt,\n- \"Output: {0->1}\" is the output template.\n\nModel
      can produce erroneous output if a prompt is not well defined. In our collaboration,
      we\u2019ll work together to refine a prompt. The process consists of two main
      steps:\n\n## Step 1\nI will provide you with the current prompt along with prediction
      examples. Each example contains the input text, the final prediction produced
      by the model, and the user feedback. User feedback indicates whether the model
      prediction is correct or not. Your task is to analyze the examples and user
      feedback, determining whether the existing instruction is describing the task
      reflected by these examples precisely, and suggests changes to the prompt to
      address the incorrect predictions.\n\n## Step 2\nNext, you will carefully review
      your reasoning in step 1, integrate the insights to refine the prompt, and provide
      me with the new prompt that improves the model\u2019s performance."}, {"role":
      "assistant", "content": "Sure, I\u2019d be happy to help you with this prompt
      engineering problem. Please provide me with the current prompt and the examples
      with user feedback."}, {"role": "user", "content": "\n## Current prompt\n...\n\n##
      Examples\n### Example #0\n\nText: 0 5 0\n\nOutput: 0 5 0\n\nUser feedback: Prediction
      is incorrect. Correct answer: \"1 5 1\"\n\n\n### Example #1\n\nText: 0 0 0\n\nOutput:
      0 0 0\n\nUser feedback: Prediction is incorrect. Correct answer: \"1 1 1\"\n\n\n\nSummarize
      your analysis about incorrect predictions and suggest changes to the prompt."},
      {"role": "assistant", "content": "### Analysis of Incorrect Predictions\n\n1.
      **Example #0**:\n   - **Input**: \"0 5 0\"\n   - **Model Output**: \"0 5 0\"\n   -
      **Correct Output**: \"1 5 1\"\n   - **Feedback**: The model''s output did not
      change the input values as expected. The correct output suggests that the model
      should be transforming the input in a specific way, likely by incrementing certain
      values.\n\n2. **Example #1**:\n   - **Input**: \"0 0 0\"\n   - **Model Output**:
      \"0 0 0\"\n   - **Correct Output**: \"1 1 1\"\n   - **Feedback**: Similar to
      Example #0, the model failed to transform the input. The correct output indicates
      that all values should be incremented from 0 to 1.\n\n### Observations\n- The
      model is not performing the expected transformation on the input values. Instead
      of modifying the input, it is simply echoing it back.\n- The correct outputs
      suggest a pattern where the model should be incrementing the values in the input.
      Specifically, it seems that:\n  - If the input contains \"0\", it should be
      transformed to \"1\".\n  - The model may need to apply a consistent transformation
      rule to all numbers in the input.\n\n### Suggested Changes to the Prompt\nTo
      improve the model''s performance, the prompt should clearly instruct the model
      to apply a transformation to the input values. Here\u2019s a refined version
      of the prompt:\n\n---\n\n**New Prompt**:\n\"Transform the input numbers by incrementing
      each number by 1. If the number is 0, change it to 1. Provide the transformed
      output as a space-separated string.\"\n\n---\n\n### Final Prompt Structure\n```\nTransform
      the input numbers by incrementing each number by 1. If the number is 0, change
      it to 1. Provide the transformed output as a space-separated string.\nText:
      {input}\nOutput: {0->1}\n```\n\nThis new prompt explicitly states the transformation
      rule, which should help the model generate the correct outputs based on the
      provided examples."}, {"role": "user", "content": "\nNow please carefully review
      your reasoning in Step 1 and help with Step 2: refining the prompt.\n\n## Current
      prompt\n...\n\n## Follow this guidance to refine the prompt:\n\n1. The new prompt
      should should describe the task precisely, and address the points raised in
      the user feedback.\n\n2. The new prompt should be similar to the current prompt,
      and only differ in the parts that address the issues you identified in Step
      1.\n    Example:\n    - Current prompt: \"Generate a summary of the input text.\"\n    -
      New prompt: \"Generate a summary of the input text. Pay attention to the original
      style.\"\n\n3. Reply only with the new prompt. Do not include input and output
      templates in the prompt.\n"}], "model": "gpt-4o-mini", "max_tokens": 1000, "seed":
      47, "temperature": 0.0}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '4863'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1RRPW/bMBDd9SsOnC1DkpU48VigAZIhQxG0Q1EYFHWS6IhHhncCmgb+7wVl2U4W
        Du/j7t3jRwagbKt2oMygxbgw5vdvvXuurNz8HPjBxpfy38OhuXv+bg7ffj2pVXL45oBGzq618S6M
        KNbTiTYRtWCaWm6ralPXN9V2JpxvcUy2Pkhe+9xZsnlVVHVebPPybnEP3hpktYPfGQDAx/ymnNTi
        X7WDYnVGHDLrHtXuIgJQ0Y8JUZrZsmgStbqSxpMgzdFfoibufHQgA4KlMAnQ5BqMDM07WDIRHZJY
        6gG1GRYyceUaHrvZtmCWoViBGTT1CFZAfNL8QJkizTo5L8MW/CRpl2bQwEEbzBmDjqkyYImW+rVa
        Eh8vp46+D9E3qRaaxvGCd5YsD/uImj2ls1h8ONmPGcCfudLpS0sqRO+C7MW/IqWBZVEvnarrV17p
        ze1Cihc9frZtb7Mlo+J3FnT7zlKPMUR76rgL+6IrNm3dFYgqO2b/AQAA//8DAJCHo2hxAgAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58a8e4867291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:02:08 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '709'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149997888'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_1d402d31ad1e35bffd1a0dcc0e3fb2fb
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "Transform the input numbers
      by incrementing each number by 1. If the number is 0, change it to 1. Return
      the transformed output as a space-separated string."}, {"role": "user", "content":
      "Text: 0 5 0"}], "model": "gpt-4o-mini", "max_tokens": 1000, "seed": 47, "temperature":
      0.0, "tool_choice": {"type": "function", "function": {"name": "Output"}}, "tools":
      [{"type": "function", "function": {"name": "Output", "description": "Correctly
      extracted `Output` with all the required parameters with correct types", "parameters":
      {"properties": {"0->1": {"description": "Output:", "title": "0->1", "type":
      "string"}}, "required": ["0->1"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '701'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA2xSS0/jMBC+51dYc25QkqYt5MCB3QUJaVVxAFQoiozrJGb9WnsiaKv+d+SktKHC
        B2s0n7+HZryNCAGxgoIAaygyZWV88b9W842d/7qeUPlXzN5/X90v5ou76ulm8wdGgWFe3zjDL9YZ
        M8pKjsLoHmaOU+RBNZ1l2TjPJ9l5Byiz4jLQaotxbmIltIizJMvjZBan53t2YwTjHgryHBFCyLa7
        Q0694h9QkGT01VHce1pzKA6PCAFnZOgA9V54pBphdASZ0ch1iK5bKQcAGiNLRqU8GvdnO6iPw6JS
        ltNW3V5v7McbTh/kzW2zWCfCPTbjgV8vvbZdoKrV7DCkAX7oFydmhICmquPOW7QtnjAJAerqVnGN
        ITVsl5DEl+kSiiWkZErSJezgG2MX/VS/7KvdYbDS1NaZV38yJ6iEFr4pHae+ywseje0tgtxLt8D2
        207AOqMslmj+cR0E0zTv9eD4b4boHkSDVA762STaJwS/9shVWQldc2ed6PYJlS2TKhmv8irhHKJd
        9AkAAP//AwAtwXx53QIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58a954efa291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:02:08 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '250'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149998956'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_bbfc257ebdbece21fab6c387dab715f3
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "Transform the input numbers
      by incrementing each number by 1. If the number is 0, change it to 1. Return
      the transformed output as a space-separated string."}, {"role": "user", "content":
      "Text: 0 0 0"}], "model": "gpt-4o-mini", "max_tokens": 1000, "seed": 47, "temperature":
      0.0, "tool_choice": {"type": "function", "function": {"name": "Output"}}, "tools":
      [{"type": "function", "function": {"name": "Output", "description": "Correctly
      extracted `Output` with all the required parameters with correct types", "parameters":
      {"properties": {"0->1": {"description": "Output:", "title": "0->1", "type":
      "string"}}, "required": ["0->1"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '701'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA2xSS2/bMAy++1cIPMeD5bjI6sOuS1C0C7AFQ7sUhiLTtlq9ZtFbgyD/fbCdJm4w
        HQSCn74HSB0ixkCVkDOQjSBpvI5vf9dmvatWfv7VLtdPm/1LeaeSzWP4sVy9wqxnuN0LSnpnfZLO
        eI2knB1h2aIg7FX5Ik3nWXaT3g6AcSXqnlZ7ijMXG2VVnCZpFieLmH8+sRunJAbI2a+IMcYOw93n
        tCW+Qc6S2XvHYAiiRsjPjxiD1um+AyIEFUhYgtkFlM4S2j667bSeAOScLqTQ+mI8nsOkvgxLaF14
        +4j3+uef9dvDcrNovjfdyj3xvw8Tv1F674dAVWfleUgT/NzPr8wYAyvMwP3Wke/oiskYiLbuDFrq
        U8NhC0n8hW8h3wJnnPEtHOED4xj9r34+VcfzYLWrfet24WpOUCmrQlO0KMKQFwI5P1r0cs/DArsP
        OwHfOuOpIPeKthfkPBv14PJvpugJJEdCT/rpTXRKCGEfCE1RKVtj61s17BMqXyRVMi+zKkGE6Bj9
        AwAA//8DAGSxWsjdAgAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58a9a9bb3291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:02:09 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '230'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149998955'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_2237fd5b4daeedfbbb256937be9dd14d
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "..."}, {"role": "user", "content":
      "Text: 1 6 1"}], "model": "gpt-4o-mini", "max_tokens": 1000, "seed": 47, "temperature":
      0.0, "tool_choice": {"type": "function", "function": {"name": "Output"}}, "tools":
      [{"type": "function", "function": {"name": "Output", "description": "Correctly
      extracted `Output` with all the required parameters with correct types", "parameters":
      {"properties": {"1->2": {"description": "Output:", "title": "1->2", "type":
      "string"}}, "required": ["1->2"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '548'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//bFJta9swEP7uXyHuczxkx11mfyiUdl0GYxsbY6VNMYp9trXpbdaZrYT8
        9yE7jdNQfRDHPXpeuNMuYgxkDQWDqhNUaafi/E+rv3a3S965fE32+/qu/rHFm8/5EvlfWASG3f7C
        ip5ZbyqrnUKS1kxw1aMgDKrJKk2XWXaR5iOgbY0q0FpHcWZjLY2MU55mMV/FybsDu7OyQg8Fe4gY
        Y2w33iGnqfEfFIwvnjsavRctQnF8xBj0VoUOCO+lJ2EIFjNYWUNoQnQzKHUCkLWqrIRSs/F0dif1
        PCyhVMnXF1effrbiTry/3wp9/fHK39b44duJ3yT95MZAzWCq45BO8GO/ODNjDIzQI/fLQG6gMyZj
        IPp20GgopIbdBpL4Mt1AsYGEvWXJBvbwgrGPXqsfD9X+OFhlW9fbrT+bEzTSSN+VPQo/5gVP1k0W
        Qe5xXODwYifgeqsdlWR/owmCq3ySg/nbzGCSHECyJNTcz3l0yAf+yRPqspGmxd71ctwmNK7kDV/W
        WcMRIdpH/wEAAP//AwAjSyfB2wIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58a9e3edc291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:02:10 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '687'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149998994'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_098ede72d7c79de4694028aed59a39fd
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "..."}, {"role": "user", "content":
      "Text: 1 1 1"}], "model": "gpt-4o-mini", "max_tokens": 1000, "seed": 47, "temperature":
      0.0, "tool_choice": {"type": "function", "function": {"name": "Output"}}, "tools":
      [{"type": "function", "function": {"name": "Output", "description": "Correctly
      extracted `Output` with all the required parameters with correct types", "parameters":
      {"properties": {"1->2": {"description": "Output:", "title": "1->2", "type":
      "string"}}, "required": ["1->2"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '548'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//bFJLa+MwEL77V4g514vlOCTxYQ9t2ZambMmhh2VTjCKPHWX1iiVD25D/
        vkjOxmlYHcQwn74HMzokhICooSTAt8xzZWW62Ldqtfzk29283tz/enhkq+fbKbd0tZsj3ASG2eyQ
        +3+sb9woK9ELoweYd8g8BlU6y/NJUUwnWQSUqVEGWmt9WphUCS3SPMuLNJuldH5ib43g6KAkvxNC
        CDnEO+TUNb5DSaJW7Ch0jrUI5fkRIdAZGTrAnBPOM+3hZgS50R51iK57KS8Ab4ysOJNyNB7O4aIe
        h8WkrMzdSzF7z183k/1y//PuabpcPv54kM2F3yD9YWOgptf8PKQL/Nwvr8wIAc1U5L703vb+ikkI
        sK7tFWofUsNhDTT9nq+hXAMllNA1HOEL45j8r347VcfzYKVpbWc27mpO0Agt3LbqkLmYF5w3drAI
        cm9xgf2XnYDtjLK+8uYP6iA4WwxyMH6bEaT0BHrjmRz7iyw55QP34TyqqhG6xc52Im4TGltlTTap
        iyZDhOSY/AUAAP//AwAiytgp2wIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58aa4ed6f291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:02:11 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '384'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149998994'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_8aa4b1af3480935aea356ce15e160f0f
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "\nA prompt is a text paragraph that outlines the
      expected actions and instructs the large language model (LLM) to generate a
      specific output. This prompt is concatenated with the input text, and the model
      then creates the required output.\nThis describes the full template how the
      prompt is concatenated with the input to produce the output:\n\n```\n\n{prompt}\nText:
      {input}\nOutput: {0->1}\n```\n\nHere:\n- \"Text: {input}\" is input template,\n-
      \"{prompt}\" is the LLM prompt,\n- \"Output: {0->1}\" is the output template.\n\nModel
      can produce erroneous output if a prompt is not well defined. In our collaboration,
      we\u2019ll work together to refine a prompt. The process consists of two main
      steps:\n\n## Step 1\nI will provide you with the current prompt along with prediction
      examples. Each example contains the input text, the final prediction produced
      by the model, and the user feedback. User feedback indicates whether the model
      prediction is correct or not. Your task is to analyze the examples and user
      feedback, determining whether the existing instruction is describing the task
      reflected by these examples precisely, and suggests changes to the prompt to
      address the incorrect predictions.\n\n## Step 2\nNext, you will carefully review
      your reasoning in step 1, integrate the insights to refine the prompt, and provide
      me with the new prompt that improves the model\u2019s performance."}, {"role":
      "assistant", "content": "Sure, I\u2019d be happy to help you with this prompt
      engineering problem. Please provide me with the current prompt and the examples
      with user feedback."}, {"role": "user", "content": "\n## Current prompt\nTransform
      the input numbers by incrementing each number by 1. If the number is 0, change
      it to 1. Return the transformed output as a space-separated string.\n\n## Examples\n###
      Example #0\n\nText: 0 5 0\n\nOutput: 1 6 1\n\nUser feedback: Prediction is incorrect.
      Correct answer: \"1 5 1\"\n\n\n### Example #1\n\nText: 0 0 0\n\nOutput: 1 1
      1\n\nUser feedback: Prediction is correct.\n\n\n\nSummarize your analysis about
      incorrect predictions and suggest changes to the prompt."}], "model": "gpt-4o-mini",
      "max_tokens": 1000, "seed": 47, "temperature": 0.0}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2307'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//vFVdb9s2FH33r7hQHgYYtiE5dpp6wICtaLEMaVekKfYwDRFNXVlcqHsV
        krIjBPnvA6kPO1uxri97MQxe3cPDcw55nyYAkcqjDUSyFE5WtZ6/fthVN2v8vKTkw8PhJ1Pw7XXC
        l9fqN3v9SzTzHbz9E6UbuhaSq1qjU0xdWRoUDj1q8mq5PF+t1udJKFSco/Ztu9rNVzyvFKn5Ml6u
        5vGreXLZd5esJNpoA79PAACewq/nSTk+RhuIZ8NKhdaKHUab8SOAyLD2K5GwVlknyEWzY1EyOaRA
        /ezsDH4koVurLHABVyTZGJQOPhrMlfTnsSmllCxgOn37KPwh4Swem6bTTUoAMIfp9Irqxk2nG8hi
        WEOcjYX3/sjwa+OGegIXkBzrny0aeIeYb4W89x+MNL4HVyIMnATZAxpQ1iOsIckWI8QNCssEBRt4
        awwbj3JbIgS1QQ14uvX/DVZIDvMATk21RQPZOgPHkF1ki9CoyDrTBAH8ehqNfYBClkPbtoUkjeAg
        LChyaGqDAZgZtHJohNbtDDSKXNHOAwk6sgFnBNmCTSXCPlz8jdHCS798IX3yVenjr0if/Kv0b06F
        59AHlXCyRBuW8LFGGY74gntg6tP0qakqYVp/lneK/KltSl7Q2nBVu+/sNyqrbBBza1jkICiHnNEC
        sQMhJTfkgueema1RqkJJMPjQqB7RlcIBk24hizOwJTc6hy2CLAXtglGQJdkMDqXSCEJrYFei6UnY
        ocNgJRRBQ32fz4iyoDsE98WgVZyrog22v4yZIjjepBPhdju0Xtk3YQ87IH8MwqV0y6Cq2vAeu0uh
        hVGuHULTyRsUQrKNwRNWNRpvVGegE/YeRpYzuALb7RyqBWvNB0/a4F5ZxbTxBP0F2yuLec8mZC+N
        bocMhF7lQzgqt207kT1W8NUb0MkdWGoUe1/7p+YnKt+gawx1vIe9MB9yKSwIsLWQOLdYC+MfXLDO
        KNot0sjzDi6ZnnovkdQojG6HvIRcfzkkJ1v+14SEIIoKw/eyHKol6vrEELFnlfe24V5xYwH9qzWG
        4QMeRt9/RoPhGvgU4WE4hmNPsbGYB4eyLEvpm/yIPUTyv3hBt/joNvAUGD2n1L1HG3iK5z8kz4F8
        1M+n53Gwad7Vhrd+CFKj9bheKFK2vDPhxfdDzDquu/bnCcAfYYA2L2Zi1Gl25/geyQOuLi47vOg4
        t4/V88uLvurYCX0sXK5Xk55iZFvrsLorFO38s6+6gVrUd3ERn+erIkaMJs+TvwAAAP//AwDsDlKl
        XggAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58aa9292d291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:02:17 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '5463'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149998491'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_0d94b65d4254e37b5efed57b7c67806e
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "\nA prompt is a text paragraph that outlines the
      expected actions and instructs the large language model (LLM) to generate a
      specific output. This prompt is concatenated with the input text, and the model
      then creates the required output.\nThis describes the full template how the
      prompt is concatenated with the input to produce the output:\n\n```\n\n{prompt}\nText:
      {input}\nOutput: {0->1}\n```\n\nHere:\n- \"Text: {input}\" is input template,\n-
      \"{prompt}\" is the LLM prompt,\n- \"Output: {0->1}\" is the output template.\n\nModel
      can produce erroneous output if a prompt is not well defined. In our collaboration,
      we\u2019ll work together to refine a prompt. The process consists of two main
      steps:\n\n## Step 1\nI will provide you with the current prompt along with prediction
      examples. Each example contains the input text, the final prediction produced
      by the model, and the user feedback. User feedback indicates whether the model
      prediction is correct or not. Your task is to analyze the examples and user
      feedback, determining whether the existing instruction is describing the task
      reflected by these examples precisely, and suggests changes to the prompt to
      address the incorrect predictions.\n\n## Step 2\nNext, you will carefully review
      your reasoning in step 1, integrate the insights to refine the prompt, and provide
      me with the new prompt that improves the model\u2019s performance."}, {"role":
      "assistant", "content": "Sure, I\u2019d be happy to help you with this prompt
      engineering problem. Please provide me with the current prompt and the examples
      with user feedback."}, {"role": "user", "content": "\n## Current prompt\nTransform
      the input numbers by incrementing each number by 1. If the number is 0, change
      it to 1. Return the transformed output as a space-separated string.\n\n## Examples\n###
      Example #0\n\nText: 0 5 0\n\nOutput: 1 6 1\n\nUser feedback: Prediction is incorrect.
      Correct answer: \"1 5 1\"\n\n\n### Example #1\n\nText: 0 0 0\n\nOutput: 1 1
      1\n\nUser feedback: Prediction is correct.\n\n\n\nSummarize your analysis about
      incorrect predictions and suggest changes to the prompt."}, {"role": "assistant",
      "content": "### Analysis of Incorrect Predictions\n\n1. **Example #0 Analysis**:\n   -
      **Input**: `0 5 0`\n   - **Model Output**: `1 6 1`\n   - **User Feedback**:
      Incorrect; the correct answer is `1 5 1`.\n   - **Reason for Error**: The model
      incorrectly incremented the number `5` to `6`. The instruction to \"increment
      each number by 1\" was interpreted too literally, leading to an incorrect transformation
      of the number `5`.\n\n2. **Example #1 Analysis**:\n   - **Input**: `0 0 0`\n   -
      **Model Output**: `1 1 1`\n   - **User Feedback**: Correct; the output matches
      the expected transformation.\n\n### Summary of Findings\nThe prompt''s instruction
      to \"increment each number by 1\" is too broad and does not account for the
      specific requirement that only `0` should be changed to `1`, while all other
      numbers should remain unchanged. This led to the model incorrectly modifying
      the number `5` in Example #0.\n\n### Suggested Changes to the Prompt\nTo improve
      the clarity of the prompt and ensure the model performs the task correctly,
      I suggest the following revision:\n\n**Revised Prompt**:\n\"Transform the input
      numbers by changing each `0` to `1` and leaving all other numbers unchanged.
      Return the transformed output as a space-separated string.\"\n\nThis revised
      prompt clearly specifies that only `0` should be transformed, while all other
      numbers should remain the same, which should help the model avoid the previous
      error.\n\n### New Prompt\nHere is the new prompt to be used:\n\n```\nTransform
      the input numbers by changing each 0 to 1 and leaving all other numbers unchanged.
      Return the transformed output as a space-separated string.\nText: {input}\nOutput:
      {0->1}\n```"}, {"role": "user", "content": "\nNow please carefully review your
      reasoning in Step 1 and help with Step 2: refining the prompt.\n\n## Current
      prompt\nTransform the input numbers by incrementing each number by 1. If the
      number is 0, change it to 1. Return the transformed output as a space-separated
      string.\n\n## Follow this guidance to refine the prompt:\n\n1. The new prompt
      should should describe the task precisely, and address the points raised in
      the user feedback.\n\n2. The new prompt should be similar to the current prompt,
      and only differ in the parts that address the issues you identified in Step
      1.\n    Example:\n    - Current prompt: \"Generate a summary of the input text.\"\n    -
      New prompt: \"Generate a summary of the input text. Pay attention to the original
      style.\"\n\n3. Reply only with the new prompt. Do not include input and output
      templates in the prompt.\n"}], "model": "gpt-4o-mini", "max_tokens": 1000, "seed":
      47, "temperature": 0.0}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '4908'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//VJFPi9swEMXv/hSDznGwHTduclwKPRWWpQulpQTZntjaSjOqNA4JS757
        kfNve9HhPf1Gb57eMwBlerUF1Y1aOudtvvk7uB8vp5+rw5fnJ3N65sPT6+tb8+34VY4ntUgEt2/Y
        yY1aduy8RTFMF7sLqAXT1LKpqlVdf1o1s+G4R5uwwUtec+4Mmbwqqjovmrz8fKVHNh1GtYVfGQDA
        +3ymnNTjUW2hWNwUhzHqAdX2fglABbZJUTpGE0WTqMXD7JgEaY7+PWiKew4OZEQw5CcBmlyLIUJ7
        gm7UNBgaAHU3QgHCUIKmHizqQ9K1tcAyYrhTE80Q9kt4QZkCzZPl9g72wJOkZ3QEDdHrDvOIXofU
        FkQJhoaluoY937e0PPjAbWqEJmvv+t6QieMuoI5MaaMo7C/4OQP4Pbc5/VeQ8oGdl53wH6Q0sCzq
        1WWgevziw642V1NYtP2INVV2zajiKQq63d7QgMEHc6l373frsmzX66YtNyo7Z/8AAAD//wMA7Xnh
        sWwCAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58acd6b01291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:02:17 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '502'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149997871'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_60b810f49d9439849b8f45e267eca241
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "Transform the input numbers
      by changing each 0 to 1 and leaving all other numbers unchanged. Return the
      transformed output as a space-separated string."}, {"role": "user", "content":
      "Text: 0 5 0"}], "model": "gpt-4o-mini", "max_tokens": 1000, "seed": 47, "temperature":
      0.0, "tool_choice": {"type": "function", "function": {"name": "Output"}}, "tools":
      [{"type": "function", "function": {"name": "Output", "description": "Correctly
      extracted `Output` with all the required parameters with correct types", "parameters":
      {"properties": {"0->1": {"description": "Output:", "title": "0->1", "type":
      "string"}}, "required": ["0->1"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '696'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA2xSO2/bMBDe9SuIm62CkhXY1VCg7hIkg5JODepAoKmTzJaviCc0qeH/XlBybMUo
        B+JwH78H7nhIGAPVQMlA7gVJ43X6+aUzT6rb/9hVX6vvy9fbbCO+3eWaN0+PG1hEhtv9QknvrE/S
        Ga+RlLMTLHsUhFE1W+X5sihulusRMK5BHWmdp7RwqVFWpTnPi5Sv0mx9Yu+dkhigZD8Txhg7jHfM
        aRt8hZLxxXvHYAiiQyjPjxiD3unYARGCCiQsweICSmcJbYxuB61nADmnaym0vhhP5zCrL8MSWtcr
        VRV/hdj4zUO4faj6ofuDdC93M79J+s2PgdrByvOQZvi5X16ZMQZWmJFbDeQHumIyBqLvBoOWYmo4
        bIGnX7ItlFvI2A3LtnCED4xj8r/6+VQdz4PVrvO924WrOUGrrAr7ukcRxrwQyPnJIso9jwscPuwE
        fO+Mp5rcb7RRMOOrSQ8u/2aGZieQHAk976+TU0IIb4HQ1K2yHfa+V+M+ofU1b/myKVqOCMkx+QcA
        AP//AwARZNRE3QIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58ad2bf63291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:02:18 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '286'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149998956'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_27426a5091866361990331688509e69b
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "Transform the input numbers
      by changing each 0 to 1 and leaving all other numbers unchanged. Return the
      transformed output as a space-separated string."}, {"role": "user", "content":
      "Text: 0 0 0"}], "model": "gpt-4o-mini", "max_tokens": 1000, "seed": 47, "temperature":
      0.0, "tool_choice": {"type": "function", "function": {"name": "Output"}}, "tools":
      [{"type": "function", "function": {"name": "Output", "description": "Correctly
      extracted `Output` with all the required parameters with correct types", "parameters":
      {"properties": {"0->1": {"description": "Output:", "title": "0->1", "type":
      "string"}}, "required": ["0->1"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '696'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//bFLJbtswEL3rK4g5WwUlK7WjQy+F0Q1FAB/apHUgUPRQZsNNIpXUMPzv
        BSXHVozyQAzm8S2Y4SEhBOQWSgJ8xwLXTqW3baMf6tX3j89q9WnV3rZt8bMQDX3KP7+sYRYZtv6D
        PLyy3nGrncIgrRlh3iELGFWzRZ7Pi+JmvhwAbbeoIq1xIS1sqqWRaU7zIqWLNFue2DsrOXooye+E
        EEIOwx1zmi3+hZLQ2WtHo/esQSjPjwiBzqrYAea99IGZALMLyK0JaGJ00ys1AYK1quJMqYvxeA6T
        +jIsplT1dX/38q2uH740ojX379c3z/e/xI/11G+U3rshkOgNPw9pgp/75ZUZIWCYHrh3fXD9tTIh
        wLqm12hCTA2HDdD0Q7aBcgMZyUi2gSO8YRyT/9WPp+p4Hqyyjets7a/mBEIa6XdVh8wPecEH60aL
        KPc4LLB/sxNwndUuVME+oYmCGV2MenD5NxM0O4HBBqam/WVySgh+7wPqSkjTYOc6OewThKuooPNt
        ISgiJMfkHwAAAP//AwDuH9Vf3QIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58ad68b18291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:02:19 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '312'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149998956'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_4afd21f2808ff2b3fe708f637f5a775f
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "..."}, {"role": "user", "content":
      "Text: 1 5 1"}], "model": "gpt-4o-mini", "max_tokens": 1000, "seed": 47, "temperature":
      0.0, "tool_choice": {"type": "function", "function": {"name": "Output"}}, "tools":
      [{"type": "function", "function": {"name": "Output", "description": "Correctly
      extracted `Output` with all the required parameters with correct types", "parameters":
      {"properties": {"1->2": {"description": "Output:", "title": "1->2", "type":
      "string"}}, "required": ["1->2"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '548'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA2xSW2+bMBR+51dY5zlMmBIYPEyq1Kq3TVVftipNhQw4xIlvw4duVZT/PhnSkEbz
        g3V0Pn8XneNdQAiIBgoC9ZphrawM89+tWtxeP2wyyRd/rr5vnp4ebqN2fpekz5cw8wxTbXiNH6wv
        tVFWchRGj3DdcYbcq9Isji+SZH6RD4AyDZee1loMExMqoUUYR3ESRllIvx7YayNq7qAgLwEhhOyG
        2+fUDf8LBYlmHx3FnWMth+L4iBDojPQdYM4Jh0wjzCawNhq59tF1L+UJgMbIsmZSTsbj2Z3U07CY
        lGXzS/9c/Hhr8u3d9TZ31f2VSOP7G3riN0q/2yHQqtf1cUgn+LFfnJkRApqpgfvYo+3xjEkIsK7t
        FdfoU8NuCTT8Fi+hWAIlc0KXsIdPjH3wv/r1UO2Pg5WmtZ2p3NmcYCW0cOuy48wNecGhsaOFl3sd
        Fth/2gnYziiLJZot114wy0c5mL7NBFJ6ANEgk1M/j4JDPnDvDrkqV0K3vLOdGLYJK1umlFZpmlU0
        h2Af/AMAAP//AwAYqYIX2wIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58ada7ebf291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:02:19 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '249'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149998994'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_45e15230bdfc2ecae69d07ccf5d13408
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "..."}, {"role": "user", "content":
      "Text: 1 1 1"}], "model": "gpt-4o-mini", "max_tokens": 1000, "seed": 47, "temperature":
      0.0, "tool_choice": {"type": "function", "function": {"name": "Output"}}, "tools":
      [{"type": "function", "function": {"name": "Output", "description": "Correctly
      extracted `Output` with all the required parameters with correct types", "parameters":
      {"properties": {"1->2": {"description": "Output:", "title": "1->2", "type":
      "string"}}, "required": ["1->2"], "type": "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '548'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//bFJLi9swEL77V4g5r4vtuE3jw8KeG0jpI7S7WYyijB119Yo0bjeE/Pdi
        2Y2zoTqIYT59D2Z0ShgDuYOKgdhzEtqpdHFoNW+bn7OV+LHcvuyX/vPq8PDpG3WvXwnueobd/kJB
        /1jvhNVOIUlrBlh45IS9aj4villZvi+zCGi7Q9XTWkdpaVMtjUyLrCjTbJ7mH0f23kqBASr2lDDG
        2CnefU6zw1eoWNSKHY0h8BahujxiDLxVfQd4CDIQN0PmERTWEJo+uumUugLIWlULrtRkPJzTVT0N
        iytVf6AuOzyuEbuHP8f192Xz5bB+VOXvK79B+uhioKYz4jKkK/zSr27MGAPDdeSuOnId3TAZA+7b
        TqOhPjWcNpCn98UGqg3kLGf5Bs7whnFO/lc/j9X5MlhlW+ftNtzMCRppZNjXHnmIeSGQdYNFL/cc
        F9i92Qk4b7WjmuwLml5wvhjkYPo2E5jnI0iWuJr6iywZ80E4BkJdN9K06J2XcZvQuDprstmubDJE
        SM7JXwAAAP//AwCXmt8w2wIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58ade3a7f291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:02:20 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '243'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149998994'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_731c8a9a52ac4f5fcb3738076e7d469b
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "\nA prompt is a text paragraph that outlines the
      expected actions and instructs the large language model (LLM) to generate a
      specific output. This prompt is concatenated with the input text, and the model
      then creates the required output.\nThis describes the full template how the
      prompt is concatenated with the input to produce the output:\n\n```\n\n{prompt}\nText:
      {0->1}\nOutput: {1->2}\n```\n\nHere:\n- \"Text: {0->1}\" is input template,\n-
      \"{prompt}\" is the LLM prompt,\n- \"Output: {1->2}\" is the output template.\n\nModel
      can produce erroneous output if a prompt is not well defined. In our collaboration,
      we\u2019ll work together to refine a prompt. The process consists of two main
      steps:\n\n## Step 1\nI will provide you with the current prompt along with prediction
      examples. Each example contains the input text, the final prediction produced
      by the model, and the user feedback. User feedback indicates whether the model
      prediction is correct or not. Your task is to analyze the examples and user
      feedback, determining whether the existing instruction is describing the task
      reflected by these examples precisely, and suggests changes to the prompt to
      address the incorrect predictions.\n\n## Step 2\nNext, you will carefully review
      your reasoning in step 1, integrate the insights to refine the prompt, and provide
      me with the new prompt that improves the model\u2019s performance."}, {"role":
      "assistant", "content": "Sure, I\u2019d be happy to help you with this prompt
      engineering problem. Please provide me with the current prompt and the examples
      with user feedback."}, {"role": "user", "content": "\n## Current prompt\n...\n\n##
      Examples\n### Example #0\n\nText: 1 5 1\n\nOutput: 1 5 1\n\nUser feedback: Prediction
      is incorrect. Correct answer: \"2 5 2\"\n\n\n### Example #1\n\nText: 1 1 1\n\nOutput:
      1 1 1\n\nUser feedback: Prediction is incorrect. Correct answer: \"2 2 2\"\n\n\n\nSummarize
      your analysis about incorrect predictions and suggest changes to the prompt."}],
      "model": "gpt-4o-mini", "max_tokens": 1000, "seed": 47, "temperature": 0.0}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2180'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//jFXbbiNFEH33VxSTByCyI9sxMvhhJYSybCQuAYIQIihpd9fM9Kanera7
        xvYoisRv8Ht8Caqei53VruBlHqZup86p6nqaAGTWZBvIdKlYV7WbffWuqNSV++n7Q8XfXa1vr8v6
        9faqfIP47W/zbCoRfvsWNQ9RF9pXtUO2njqzDqgYJetivVxerlZfrObJUHmDTsKKmmcrP6ss2dly
        vlzN5uvZ4ss+uvRWY8w28McEAOApfQUnGTxkG0i50p8KY1QFZpvRCSAL3smfTMVoIyvibHo0ak+M
        lKCfnZ3B16RcG20En8M1aR8CaoabgMZq6Sfe0R0tLuD8/FcyGCSdsVQAlwi3Kj6en2/gtkTAgxIK
        ItTB76xBA5aM1YoRuFSc/FPzYCPgoUbNaIA9cFAUcx+q5GKpbhioqbYYIliC6CuEvWqnsG26LLoJ
        AYmlUFUzGI8RyDNohyq4FmKN2uZt8h2TK+kFQuMwXiS8vuG64VSCT+HHpigw8vugY+kbZ2ArCHXA
        ComFBVS67NEOmboOti0sLoS6ZaIuYoDXiGar9MhYIz/z/qdQ4qy2LA2wYozvIfhUmB1FARUSkl4u
        RWbgPXYcjYa4x5BatnFUJH5AEmEw9875/aDuUaSXJDpfWD2FfWl1KZHOPqJrwTQocipw0o7PQTsV
        LLcDL51ciZNL4eRGMWMg+Bm1L8hKamHmmmDruRwFmabgTi2ppj3JUCMJUx+amF4dNJ0GXed1X4wQ
        TRSYWxznRQW2unGyry+xil/RWIMnTGGeo2a7Q9emVmSFfulGBg18UyoqMBWQkJuURtxuPdhKFMKX
        imJIvJLG6WnhftpOZsJS5NDoU9HYH7v9j0GENxjwn7/+jqAgYG4JDewwRJHT5yeVN11P8APuR/QP
        Dw939Ltv0syxio9oYG+5/J+bwHgYULz24aN+02GAj/Mba9+9Naei7pRrcIjsxiIJcYsH3sDTfPZq
        8XxHPybDBp4Ws1fL576HQa2qUqGVvnu57miWFpJwPwgwviXDKiKotHkn/I+z1KsIn32UEGn/8wup
        c83HRVUQOShblJz7sFfBjCp3hRSDcrag2NH94pkq7A5pWMJ+XEp09Qm+AglD9/4eH4QTxm4cqojg
        kKFCeCS/B5tD6xvYp3Sy16m94DUOmrNs0wlRPgxBpdohKGohbwKXGECZt01koSO9spUl80nW36Hn
        8YA5X9TBb+XYUePc+D+3ZGN5H1BFT3KsIvu6C3+eAPyZDmXz4vZlHaZ79o9IknC1Wnf5suN9Plov
        l4OVPSt3NKzXq0kPMYttZKzuc0sFhjrY7nDm9f08n1+aVT5HzCbPk38BAAD//wMAi4ejD0YIAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58ae21e9c291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:02:26 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '6163'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149998524'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_e5cbcc843a2af7d330bbfcdf0e0dc698
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "\nA prompt is a text paragraph that outlines the
      expected actions and instructs the large language model (LLM) to generate a
      specific output. This prompt is concatenated with the input text, and the model
      then creates the required output.\nThis describes the full template how the
      prompt is concatenated with the input to produce the output:\n\n```\n\n{prompt}\nText:
      {0->1}\nOutput: {1->2}\n```\n\nHere:\n- \"Text: {0->1}\" is input template,\n-
      \"{prompt}\" is the LLM prompt,\n- \"Output: {1->2}\" is the output template.\n\nModel
      can produce erroneous output if a prompt is not well defined. In our collaboration,
      we\u2019ll work together to refine a prompt. The process consists of two main
      steps:\n\n## Step 1\nI will provide you with the current prompt along with prediction
      examples. Each example contains the input text, the final prediction produced
      by the model, and the user feedback. User feedback indicates whether the model
      prediction is correct or not. Your task is to analyze the examples and user
      feedback, determining whether the existing instruction is describing the task
      reflected by these examples precisely, and suggests changes to the prompt to
      address the incorrect predictions.\n\n## Step 2\nNext, you will carefully review
      your reasoning in step 1, integrate the insights to refine the prompt, and provide
      me with the new prompt that improves the model\u2019s performance."}, {"role":
      "assistant", "content": "Sure, I\u2019d be happy to help you with this prompt
      engineering problem. Please provide me with the current prompt and the examples
      with user feedback."}, {"role": "user", "content": "\n## Current prompt\n...\n\n##
      Examples\n### Example #0\n\nText: 1 5 1\n\nOutput: 1 5 1\n\nUser feedback: Prediction
      is incorrect. Correct answer: \"2 5 2\"\n\n\n### Example #1\n\nText: 1 1 1\n\nOutput:
      1 1 1\n\nUser feedback: Prediction is incorrect. Correct answer: \"2 2 2\"\n\n\n\nSummarize
      your analysis about incorrect predictions and suggest changes to the prompt."},
      {"role": "assistant", "content": "### Analysis of Incorrect Predictions\n\n1.
      **Understanding the Task**: The examples provided indicate that the model is
      expected to transform the input numbers in some way, but the current prompt
      does not clearly specify the transformation rules. The outputs in the examples
      suggest that the model should be incrementing each number in the input by 1.\n\n2.
      **User Feedback**: The user feedback explicitly states that the model''s predictions
      are incorrect and provides the correct answers. This indicates that the model
      is not following the expected transformation logic, which is likely due to a
      lack of clarity in the prompt.\n\n3. **Pattern Recognition**: In both examples,
      the output is consistently the input numbers incremented by 1. This pattern
      needs to be clearly articulated in the prompt to guide the model effectively.\n\n###
      Suggested Changes to the Prompt\n\nTo improve the model''s performance, the
      prompt should explicitly instruct the model to increment each number in the
      input by 1. Here\u2019s a refined version of the prompt:\n\n## New Prompt\n```\nYou
      are tasked with incrementing each number in the input text by 1. For each number
      in the input, provide the corresponding incremented value in the output.\n\nText:
      {0->1}\nOutput: {1->2}\n```\n\n### Summary of Changes\n- The new prompt clearly
      states the action the model needs to perform (incrementing each number by 1).\n-
      It provides a straightforward instruction that aligns with the examples given,
      which should help the model generate the correct output.\n\nPlease let me know
      if you would like to proceed with this new prompt or if you have any further
      adjustments in mind!"}, {"role": "user", "content": "\nNow please carefully
      review your reasoning in Step 1 and help with Step 2: refining the prompt.\n\n##
      Current prompt\n...\n\n## Follow this guidance to refine the prompt:\n\n1. The
      new prompt should should describe the task precisely, and address the points
      raised in the user feedback.\n\n2. The new prompt should be similar to the current
      prompt, and only differ in the parts that address the issues you identified
      in Step 1.\n    Example:\n    - Current prompt: \"Generate a summary of the
      input text.\"\n    - New prompt: \"Generate a summary of the input text. Pay
      attention to the original style.\"\n\n3. Reply only with the new prompt. Do
      not include input and output templates in the prompt.\n"}], "model": "gpt-4o-mini",
      "max_tokens": 1000, "seed": 47, "temperature": 0.0}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '4607'
      content-type:
      - application/json
      cookie:
      - __cf_bm=T.6MCo_8Uq9MSD5.RiIcB6eOKIkFX0KNtLqAM29M8kQ-1722344231-1.0.1.1-dLrWRaTFlxF0SNLOsFnn4_ghF.jgeHKALcppUDovGxhXu1_KBPt5DgimA5tQrhbGYgbE_KO1jJn4FA6HRIgwzw;
        _cfuvid=c9GhqWHzprkf1_2Ur1z5H_hOS0APcsq3E6L17OoRSHk-1722344231266-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.5
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAAwAAAP//dFFNr9MwELznV6x8bqo0L6997Q0hkDhwBAkQqlxnk5jau372prR66n9H
        +WgLBy4+zOyMZ2ffMgBla7UDZTotxgeXb19b352f19/Xr/GraGqKd1+Op/fd5vOx+6QWg4IPv9DI
        TbU07INDsUwTbSJqwcF1tSnLp6p6rjYj4blGN8jaIHnFubdk87Ioq7zY5KuXWd2xNZjUDn5kAABv
        4zvkpBrPagfF4oZ4TEm3qHb3IQAV2Q2I0inZJJpELR6kYRKkMfo37kFHBNHpiDX8ttKBJRPRI4ml
        FlCbDqj3B4xgCaRDsBR6AcGzwOECqyV85PjfuQWEyCdb4wgZjhFTYKoH7/tHWMNJux5vSu4l9LKE
        D5T6IVynBbRzs3+aEkdNqeHosZ5sjbjLUs1bXu/1OG5D5MNQJfXO3fHGkk3dPqJOTEMVSThM8msG
        8HM8Q/9PsypE9kH2wkekwXBbvkx+6nH9B1utZlJYtPtLtd5mc0KVLknQ7xtLLcYQ7XSVJuyLpniq
        q6ZAVNk1+wMAAP//AwDPr8oNowIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8ab58b0afc8f291f-ORD
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 30 Jul 2024 13:02:28 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - heartex
      openai-processing-ms:
      - '1214'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '30000'
      x-ratelimit-limit-tokens:
      - '150000000'
      x-ratelimit-remaining-requests:
      - '29999'
      x-ratelimit-remaining-tokens:
      - '149997944'
      x-ratelimit-reset-requests:
      - 2ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_147fdb7032c6819a18835932a6261d9a
    status:
      code: 200
      message: OK
version: 1
