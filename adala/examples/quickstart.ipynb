{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6c119c3",
   "metadata": {},
   "source": [
    "# ADALA Quickstart\n",
    "\n",
    "In this notebook, we are going to run through some of the common tasks for creating data labeling agents with ADALA. In this example, we're going to create a data labeling agent for a text classification task - labeling our text samples as either \"Subjective or \"Objective\" statements. \n",
    "\n",
    "This agent will be LLM-based, so we will use [OpenAI's API](https://platform.openai.com/). You will to generate an API key and set it as an environment variable as follows: \n",
    "\n",
    "```\n",
    "export OPENAI_API_KEY=your_openai_api_key\n",
    "```\n",
    "\n",
    "Now, let's begin. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c19afc",
   "metadata": {},
   "source": [
    "## Dataset Creation\n",
    "First, let's use a dataset of product reviews stored in pandas dataframe. This will help us manage our data as we add more attributes, like predictions and labels for subjectivity and objectivity over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d5b37a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The mic is great.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will order from them again!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not loud enough and doesn't turn on like it sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The phone doesn't seem to accept anything exce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All three broke within two months of use.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                  The mic is great.\n",
       "1                        Will order from them again!\n",
       "2  Not loud enough and doesn't turn on like it sh...\n",
       "3  The phone doesn't seem to accept anything exce...\n",
       "4          All three broke within two months of use."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "texts = [\n",
    "    \"The mic is great.\",\n",
    "    \"Will order from them again!\",\n",
    "    \"Not loud enough and doesn't turn on like it should.\",\n",
    "    \"The phone doesn't seem to accept anything except CBR mp3s\",\n",
    "    \"All three broke within two months of use.\"\n",
    "]\n",
    "df = pd.DataFrame(texts, columns=['text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc201b3",
   "metadata": {},
   "source": [
    "## Create Agent\n",
    "\n",
    "Agent's abilities are defined as **\"Skills\"**. Each agent can possess many different skills. In our case, this agent only has one labeling skill, to produce a classification of Subjective or Objective for a given piece of text. \n",
    "\n",
    "To define this skill, we will leverage an LLM, passing it instructions and the set of labeles we expect to receive back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1310fce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agent(environment=Environment(dataset=DataFrameDataset(input_data_field='text', df=                                                text  ground_truth\n",
       "0                                  The mic is great.           NaN\n",
       "1                        Will order from them again!           NaN\n",
       "2  Not loud enough and doesn't turn on like it sh...           NaN\n",
       "3  The phone doesn't seem to accept anything exce...           NaN\n",
       "4          All three broke within two months of use.           NaN, ground_truth_column='ground_truth')), skills=LinearSkillSet(skills={'skill_0': ClassificationSkill(name='subjectivity_detection', instructions='Classify a product review as either expressing \"Subjective\" or \"Objective\" statements.', description='Understanding subjective and objective statements from text.', input_template='Input: {{{{{input}}}}}', output_template=\"Output: {{{{select 'predictions' options=labels logprobs='score'}}}}\", validation_fields=['predictions'], labels=['Subjective', 'Objective'], prediction_field='predictions')}, skill_sequence=['skill_0']), memory=None, runtimes={'openai': LLMRuntime(verbose=False, llm_runtime_type=<LLMRuntimeModelType.OpenAI: 'OpenAI'>, llm_params={'model': 'gpt-3.5-turbo-instruct'}), 'openai-gpt4': LLMRuntime(verbose=False, llm_runtime_type=<LLMRuntimeModelType.OpenAI: 'OpenAI'>, llm_params={'model': 'gpt-4'})}, default_runtime='openai')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from adala.agents import Agent\n",
    "from adala.datasets import DataFrameDataset\n",
    "from adala.skills import ClassificationSkill\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    # connect to a dataset\n",
    "    environment=DataFrameDataset(df=df, input_data_field='text'),\n",
    "    \n",
    "    # define the agent's labeling skill\n",
    "    skills=ClassificationSkill(\n",
    "        name='subjectivity_detection',\n",
    "        description='Understanding subjective and objective statements from text.',\n",
    "        instructions='Classify a product review as either expressing \"Subjective\" or \"Objective\" statements.',\n",
    "        labels=['Subjective', 'Objective']\n",
    "    )\n",
    ")\n",
    "\n",
    "agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8340dde8",
   "metadata": {},
   "source": [
    "## Running the Agent\n",
    "We will now apply the skill to each of the tasks in our dataframe by running the agent. Our result will be a dataframe that we'll combine with our original data to view together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "372405da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d168bf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.environment = Environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "666c8d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>predictions</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Subjective</td>\n",
       "      <td>{'Subjective': -0.02697588099999997, 'Objectiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will order from them again!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Subjective</td>\n",
       "      <td>{'Subjective': -0.11282212000000001, 'Objectiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not loud enough and doesn't turn on like it sh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Subjective</td>\n",
       "      <td>{'Subjective': -0.014163457000000034, 'Objecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The phone doesn't seem to accept anything exce...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Objective</td>\n",
       "      <td>{'Subjective': -2.0720863, 'Objective': -0.134...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All three broke within two months of use.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Objective</td>\n",
       "      <td>{'Subjective': -2.1821797, 'Objective': -0.119...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  ground_truth  \\\n",
       "0                                  The mic is great.           NaN   \n",
       "1                        Will order from them again!           NaN   \n",
       "2  Not loud enough and doesn't turn on like it sh...           NaN   \n",
       "3  The phone doesn't seem to accept anything exce...           NaN   \n",
       "4          All three broke within two months of use.           NaN   \n",
       "\n",
       "  predictions                                              score  \n",
       "0  Subjective  {'Subjective': -0.02697588099999997, 'Objectiv...  \n",
       "1  Subjective  {'Subjective': -0.11282212000000001, 'Objectiv...  \n",
       "2  Subjective  {'Subjective': -0.014163457000000034, 'Objecti...  \n",
       "3   Objective  {'Subjective': -2.0720863, 'Objective': -0.134...  \n",
       "4   Objective  {'Subjective': -2.1821797, 'Objective': -0.119...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience = agent.apply_skills()\n",
    "pd.concat((df, experience.predictions), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d49385",
   "metadata": {},
   "source": [
    "## Labeling the Data\n",
    "We now have some basic predictions for our data. Now, these predictions could be all correct or wildly incorrect, but we don't know at this point. We need to incorporate an annotation team to provide feedback. Since this is a quickstart, we will apply some labels to the dataframe directly. Let's fix them and create a _ground truth_ that is reliable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f2bf273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0, 'ground_truth'] = 'Subjective'\n",
    "df.loc[1, 'ground_truth'] = 'Subjective'\n",
    "df.loc[2, 'ground_truth'] = 'Objective'\n",
    "df.loc[3, 'ground_truth'] = 'Objective'\n",
    "df.loc[4, 'ground_truth'] = 'Objective'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449f1081",
   "metadata": {},
   "source": [
    "## Improving the Agent\n",
    "Now that we have ground truth labels for our data, we can ask our agent to learn and improve itself by using it as a guide. \n",
    "\n",
    "We can see in the output:\n",
    "- System Prompt - the agent prompt used to improve our labeling skill\n",
    "- User Prompt - the original LLM prompt we created for our skill\n",
    "- Assistant Prompt - our updated prompt learned from our agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "336b28a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"guidance-stop-button-ad7f778c-ce82-4069-8e1e-55016a9d5da7\" style=\"cursor: pointer; margin: 0px; display: none; float: right; padding: 3px; border-radius: 4px 4px 4px 4px; border: 0px solid rgba(127, 127, 127, 1); padding-left: 10px; padding-right: 10px; font-size: 13px; background-color: rgba(127, 127, 127, 0.25);\">Stop program</div><div id=\"guidance-content-ad7f778c-ce82-4069-8e1e-55016a9d5da7\"><pre style='margin: 0px; padding: 0px; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>system</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>LLM prompt was created by concatenating instructions with text input:\n",
       "\n",
       "Prediction = LLM(Input, Instructions)\n",
       "\n",
       "We expect the prediction to be equal to the ground truth.\n",
       "Your task is to craft a revised concise instruction for the LLM. Follow best practices for LLM prompt engineering.\n",
       "Include 2-3 examples at the end of your response to demonstrate how the new instruction would be applied.\n",
       "Use the following format for your examples:\n",
       "Input: ...\n",
       "Output: ...</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>user</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'>Old instruction: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{old_instruction}}'>Classify a product review as either expressing &quot;Subjective&quot; or &quot;Objective&quot; statements.</span>\n",
       "Errors: <span style='opacity: 1.0; display: inline; background-color: rgba(165, 165, 165, 0.1);' title='{{#each errors}}\n",
       "Input: {{this.input}}\n",
       "Prediction: {{this.prediction}}\n",
       "Ground truth: {{this.ground_truth}}\n",
       "{{/each}}'>\n",
       "Input: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this.input}}'>Input: Not loud enough and doesn&#x27;t turn on like it should.</span>\n",
       "Prediction: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this.prediction}}'>Subjective</span>\n",
       "Ground truth: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{this.ground_truth}}'>Objective</span>\n",
       "</span>\n",
       "New instruction:</div></div><div style='display: flex; border-bottom: 1px solid rgba(127, 127, 127, 0.2); align-items: center;'><div style='flex: 0 0 80px; opacity: 0.5;'>assistant</div><div style='flex-grow: 1; padding: 5px; padding-top: 10px; padding-bottom: 10px; margin-top: 0px; white-space: pre-wrap; margin-bottom: 0px;'><span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{gen &#x27;new_instruction&#x27;}}'>Determine whether the given product review contains &quot;Subjective&quot; (based on personal feelings, tastes, or opinions) or &quot;Objective&quot; (based on facts or observable phenomena) statements.\n",
       "\n",
       "Examples:\n",
       "Input: The camera quality is 12 megapixels.\n",
       "Output: Objective\n",
       "\n",
       "Input: I think the camera quality is not good enough.\n",
       "Output: Subjective\n",
       "\n",
       "Input: The laptop has a 15-inch screen.\n",
       "Output: Objective</span></div></div></pre></div>\n",
       "<script type=\"text/javascript\">(()=>{var t={296:(t,e,n)=>{var i=NaN,o=\"[object Symbol]\",r=/^\\s+|\\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,s=/^0b[01]+$/i,c=/^0o[0-7]+$/i,d=parseInt,u=\"object\"==typeof n.g&&n.g&&n.g.Object===Object&&n.g,l=\"object\"==typeof self&&self&&self.Object===Object&&self,f=u||l||Function(\"return this\")(),h=Object.prototype.toString,p=Math.max,m=Math.min,g=function(){return f.Date.now()};function b(t){var e=typeof t;return!!t&&(\"object\"==e||\"function\"==e)}function y(t){if(\"number\"==typeof t)return t;if(function(t){return\"symbol\"==typeof t||function(t){return!!t&&\"object\"==typeof t}(t)&&h.call(t)==o}(t))return i;if(b(t)){var e=\"function\"==typeof t.valueOf?t.valueOf():t;t=b(e)?e+\"\":e}if(\"string\"!=typeof t)return 0===t?t:+t;t=t.replace(r,\"\");var n=s.test(t);return n||c.test(t)?d(t.slice(2),n?2:8):a.test(t)?i:+t}t.exports=function(t,e,n){var i,o,r,a,s,c,d=0,u=!1,l=!1,f=!0;if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");function h(e){var n=i,r=o;return i=o=void 0,d=e,a=t.apply(r,n)}function v(t){var n=t-c;return void 0===c||n>=e||n<0||l&&t-d>=r}function _(){var t=g();if(v(t))return w(t);s=setTimeout(_,function(t){var n=e-(t-c);return l?m(n,r-(t-d)):n}(t))}function w(t){return s=void 0,f&&i?h(t):(i=o=void 0,a)}function j(){var t=g(),n=v(t);if(i=arguments,o=this,c=t,n){if(void 0===s)return function(t){return d=t,s=setTimeout(_,e),u?h(t):a}(c);if(l)return s=setTimeout(_,e),h(c)}return void 0===s&&(s=setTimeout(_,e)),a}return e=y(e)||0,b(n)&&(u=!!n.leading,r=(l=\"maxWait\"in n)?p(y(n.maxWait)||0,e):r,f=\"trailing\"in n?!!n.trailing:f),j.cancel=function(){void 0!==s&&clearTimeout(s),d=0,i=c=o=s=void 0},j.flush=function(){return void 0===s?a:w(g())},j}},777:t=>{var e,n,i=Math.max,o=(e=function(t,e){return function(t,e,n){if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");return setTimeout((function(){t.apply(void 0,n)}),1)}(t,0,e)},n=i(void 0===n?e.length-1:n,0),function(){for(var t=arguments,o=-1,r=i(t.length-n,0),a=Array(r);++o<r;)a[o]=t[n+o];o=-1;for(var s=Array(n+1);++o<n;)s[o]=t[o];return s[n]=a,function(t,e,n){switch(n.length){case 0:return t.call(e);case 1:return t.call(e,n[0]);case 2:return t.call(e,n[0],n[1]);case 3:return t.call(e,n[0],n[1],n[2])}return t.apply(e,n)}(e,this,s)});t.exports=o}},e={};function n(i){var o=e[i];if(void 0!==o)return o.exports;var r=e[i]={exports:{}};return t[i](r,r.exports,n),r.exports}n.n=t=>{var e=t&&t.__esModule?()=>t.default:()=>t;return n.d(e,{a:e}),e},n.d=(t,e)=>{for(var i in e)n.o(e,i)&&!n.o(t,i)&&Object.defineProperty(t,i,{enumerable:!0,get:e[i]})},n.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(t){if(\"object\"==typeof window)return window}}(),n.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),(()=>{\"use strict\";const t=t=>{const e=new Set;do{for(const n of Reflect.ownKeys(t))e.add([t,n])}while((t=Reflect.getPrototypeOf(t))&&t!==Object.prototype);return e};function e(e,{include:n,exclude:i}={}){const o=t=>{const e=e=>\"string\"==typeof e?t===e:e.test(t);return n?n.some(e):!i||!i.some(e)};for(const[n,i]of t(e.constructor.prototype)){if(\"constructor\"===i||!o(i))continue;const t=Reflect.getOwnPropertyDescriptor(n,i);t&&\"function\"==typeof t.value&&(e[i]=e[i].bind(e))}return e}var i=n(777),o=n.n(i),r=n(296),a=n.n(r);class s{constructor(t,n){e(this),this.interfaceId=t,this.callbackMap={},this.data={},this.pendingData={},this.jcomm=new c(\"guidance_interface_target_\"+this.interfaceId,this.updateData,\"open\"),this.debouncedSendPendingData500=a()(this.sendPendingData,500),this.debouncedSendPendingData1000=a()(this.sendPendingData,1e3),n&&o()(n)}send(t,e){this.addPendingData(t,e),this.sendPendingData()}sendEvent(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.sendPendingData()}debouncedSendEvent500(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.debouncedSendPendingData500()}debouncedSend500(t,e){this.addPendingData(t,e),this.debouncedSendPendingData500()}debouncedSend1000(t,e){this.addPendingData(t,e),this.debouncedSendPendingData1000()}addPendingData(t,e){Array.isArray(t)||(t=[t]);for(const n in t)this.pendingData[t[n]]=e}updateData(t){t=JSON.parse(t.data);for(const e in t)this.data[e]=t[e];for(const e in t)e in this.callbackMap&&this.callbackMap[e](this.data[e])}subscribe(t,e){this.callbackMap[t]=e,o()((e=>this.callbackMap[t](this.data[t])))}sendPendingData(){this.jcomm.send_data(this.pendingData),this.pendingData={}}}class c{constructor(t,e,n=\"open\"){this._fire_callback=this._fire_callback.bind(this),this._register=this._register.bind(this),this.jcomm=void 0,this.callback=e,void 0!==window.Jupyter?\"register\"===n?Jupyter.notebook.kernel.comm_manager.register_target(t,this._register):(this.jcomm=Jupyter.notebook.kernel.comm_manager.new_comm(t),this.jcomm.on_msg(this._fire_callback)):void 0!==window._mgr&&(\"register\"===n?window._mgr.widgetManager.proxyKernel.registerCommTarget(t,this._register):(this.jcomm=window._mgr.widgetManager.proxyKernel.createComm(t),this.jcomm.open({},\"\"),this.jcomm.onMsg=this._fire_callback))}send_data(t){void 0!==this.jcomm?this.jcomm.send(t):console.error(\"Jupyter comm module not yet loaded! So we can't send the message.\")}_register(t,e){this.jcomm=t,this.jcomm.on_msg(this._fire_callback)}_fire_callback(t){this.callback(t.content.data)}}class d{constructor(t,n){e(this),this.id=t,this.comm=new s(t),this.comm.subscribe(\"append\",this.appendData),this.comm.subscribe(\"replace\",this.replaceData),this.comm.subscribe(\"event\",this.eventOccurred),this.element=document.getElementById(\"guidance-content-\"+t),this.stop_button=document.getElementById(\"guidance-stop-button-\"+t),this.stop_button.onclick=()=>this.comm.send(\"event\",\"stop\")}appendData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML+=t)}replaceData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML=t)}eventOccurred(t){\"complete\"===t&&(this.stop_button.style.display=\"none\")}}window._guidanceDisplay=function(t,e){return new d(t,e)}})()})();; window._guidanceDisplay(\"ad7f778c-ce82-4069-8e1e-55016a9d5da7\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learn_results = agent.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00578238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determine whether the given product review contains \"Subjective\" (based on personal feelings, tastes, or opinions) or \"Objective\" (based on facts or observable phenomena) statements.\n",
      "\n",
      "Examples:\n",
      "Input: The camera quality is 12 megapixels.\n",
      "Output: Objective\n",
      "\n",
      "Input: I think the camera quality is not good enough.\n",
      "Output: Subjective\n",
      "\n",
      "Input: The laptop has a 15-inch screen.\n",
      "Output: Objective\n"
     ]
    }
   ],
   "source": [
    "print(learn_results.updated_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7e96cb",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c653a8",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "We can incorporate our updated instructions into our agent's skill, and run it on new data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74671e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Output: {{{{gen 'predictions'}}}}\".format(a='aaaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0778ba74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}